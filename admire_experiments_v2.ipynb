{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aErtAe0NV-9S",
        "yPbvQvgBUFsO",
        "uZgJsl5kTP6X",
        "xWGGZrLU4UqP",
        "HHui7nG3OjuZ",
        "i6n4c9bBe_6-",
        "6s2KxV54fG5j"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46e263745bfe42cba1641ccd22a583df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_009c03518f504c37929deeb8fdc1f45f",
              "IPY_MODEL_6f63427ed5524f2b853db233a9930ba1",
              "IPY_MODEL_c9996590005b4a6e8452ab677d8b8bdd"
            ],
            "layout": "IPY_MODEL_e8d60c1dc5984c828b91609211e2542e"
          }
        },
        "009c03518f504c37929deeb8fdc1f45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_789460fd175a46dfbaeec46cada512b7",
            "placeholder": "​",
            "style": "IPY_MODEL_a16b29c632334c38afaa2f0c5300d17a",
            "value": "open_clip_pytorch_model.bin: 100%"
          }
        },
        "6f63427ed5524f2b853db233a9930ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f90ee054b17415795c3c85d1984c96d",
            "max": 605219813,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fc90f4f752141dfb14c4d4e02c85c1a",
            "value": 605219813
          }
        },
        "c9996590005b4a6e8452ab677d8b8bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_322054a5c1c547d197c1213ebed9ffea",
            "placeholder": "​",
            "style": "IPY_MODEL_56537b9780ab48489916fc4ad79ff42f",
            "value": " 605M/605M [00:02&lt;00:00, 231MB/s]"
          }
        },
        "e8d60c1dc5984c828b91609211e2542e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "789460fd175a46dfbaeec46cada512b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a16b29c632334c38afaa2f0c5300d17a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f90ee054b17415795c3c85d1984c96d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fc90f4f752141dfb14c4d4e02c85c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "322054a5c1c547d197c1213ebed9ffea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56537b9780ab48489916fc4ad79ff42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azernik/semeval_2025_task1/blob/main/admire_experiments_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup and Preprocessing"
      ],
      "metadata": {
        "id": "22DMs3xNaE-K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UMi9EZE4ZGFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c169e65-afb2-455b-fbff-77a33c1273a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# for downloading the train zip from Drive\n",
        "!pip install -q gdown\n",
        "\n",
        "import gdown\n",
        "\n",
        "# install clip\n",
        "!pip install -q ftfy regex tqdm\n",
        "!pip install -q git+https://github.com/openai/CLIP.git\n",
        "\n",
        "import clip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anyio==3.5.0 openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
      ],
      "metadata": {
        "id": "6cAArqDy5BqN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download taskA file from Adam's Drive (public) and unzip\n",
        "file_id = \"105JdQU_u98w_xSYaNNSj-r4RsyTPXZEF\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "gdown.download(url, \"taskA.zip\", quiet=True)\n",
        "! unzip -q - taskA.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "aFXAYlFl8urF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495cb77e-6627-4323-be84-ea41acfca81e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace train/acid test/02817176209.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# define locations\n",
        "taska_folder = \"train\"\n",
        "taska_tsv_filename = \"subtask_a_train.tsv\"\n",
        "\n",
        "# load data\n",
        "df = pd.read_csv(f\"{taska_folder}/{taska_tsv_filename}\", delimiter=\"\\t\")\n",
        "\n",
        "# fix incorrect row in dataset\n",
        "df.loc[df['compound'] == \"pain in the neck\", 'sentence_type'] = 'literal'"
      ],
      "metadata": {
        "id": "1MtprhczrZL8",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df[['compound', 'sentence', 'sentence_type', 'expected_order_indices']]"
      ],
      "metadata": {
        "id": "DVyUOGFLsZ4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "# Preprocess dataframe (image paths, etc.)\n",
        "image_name_cols = ['image1_name', 'image2_name', 'image3_name', 'image4_name', 'image5_name']\n",
        "df['image_paths'] = df.apply(lambda row: [os.path.join(taska_folder, row['compound'].replace(\"'\", \"_\"), row[image_name]) for image_name in image_name_cols], axis=1)\n",
        "df['image_idx_map'] = df.apply(lambda row: {row[name]: i for i, name in enumerate(image_name_cols)}, axis=1)\n",
        "df['expected_order_indices'] = df.apply(lambda row: [row['image_idx_map'][name] for name in literal_eval(row['expected_order'])], axis=1)"
      ],
      "metadata": {
        "id": "PoELS4WoZtci"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model-specific functions"
      ],
      "metadata": {
        "id": "PIKWFMqPumBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from ast import literal_eval\n",
        "\n",
        "def get_image_ranking_clip(model, image_processor, image_paths, sentence):\n",
        "    image_inputs = torch.stack([image_processor(Image.open(ipath)) for ipath in image_paths]).to(device)\n",
        "    text_input = clip.tokenize(sentence).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # compute embeddings\n",
        "        image_features = model.encode_image(image_inputs)\n",
        "        text_features = model.encode_text(text_input)\n",
        "\n",
        "    # normalize features\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # compute similarity scores\n",
        "    similarity = (100.0 * text_features @ image_features.T).softmax(dim=-1)\n",
        "\n",
        "    # rank images by similarity\n",
        "    probs, indices = similarity[0].topk(5)\n",
        "    return probs, indices"
      ],
      "metadata": {
        "id": "EWeSM7JpujrE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_ranking_clip_multi_text(model, image_processor, image_paths, text):\n",
        "    image_inputs = torch.stack([image_processor(Image.open(ipath)) for ipath in image_paths]).to(device)\n",
        "\n",
        "    text_inputs = []\n",
        "    for sentence in text:\n",
        "      text_inputs.append(clip.tokenize(sentence).to(device))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # compute embeddings\n",
        "        image_features = model.encode_image(image_inputs)\n",
        "\n",
        "    text_features = torch.zeros((4, image_features.shape[-1]), dtype=torch.float16).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, ti in enumerate(text_inputs):\n",
        "            text_features[i] = model.encode_text(ti)\n",
        "    text_features.mean(dim=0)\n",
        "\n",
        "    # normalize features\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # compute similarity scores\n",
        "    similarity = (100.0 * text_features @ image_features.T).softmax(dim=-1)\n",
        "\n",
        "    # rank images by similarity\n",
        "    probs, indices = similarity[0].topk(5)\n",
        "    return probs, indices"
      ],
      "metadata": {
        "id": "usRNGVJvbBEa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_ranking_align(model, processor, image_paths, sentence):\n",
        "    image_inputs = [Image.open(ipath) for ipath in image_paths]\n",
        "    inputs = processor(images=image_inputs ,text=sentence, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits_per_text = outputs.logits_per_text[0]\n",
        "    probs = logits_per_text.softmax(dim=-1)\n",
        "    ids_sorted = torch.argsort(probs, descending=True)\n",
        "    return probs[ids_sorted], ids_sorted"
      ],
      "metadata": {
        "id": "rCxWY_tFB0Nj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open_clip_torch\n",
        "import open_clip\n",
        "\n",
        "def openclip_image_ranking(model, image_processor, tokenizer, image_paths, sentence):\n",
        "    image_inputs = torch.stack([preprocess_openclip(Image.open(ipath)) for ipath in image_paths]).to(device)\n",
        "    text_input = tokenizer([sentence]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        image_features = model.encode_image(image_inputs)\n",
        "        text_features = model.encode_text(text_input)\n",
        "\n",
        "    # normalise features\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # dot product & softmax\n",
        "    similarity = (100.0 * text_features @ image_features.T).softmax(dim=-1)\n",
        "\n",
        "    # order by similarity\n",
        "    probs, indices = similarity[0].topk(5)\n",
        "    return probs, indices"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TNOFQXLmNBQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e26d4c9-154d-4c4d-8be2-3638e51e8d96"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: open_clip_torch in /usr/local/lib/python3.10/dist-packages (2.29.0)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.20.1+cu121)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2024.9.11)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (6.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.26.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.4.5)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (1.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->open_clip_torch) (1.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch) (0.2.13)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### General functions for experiment execution"
      ],
      "metadata": {
        "id": "G-CBChVGeHoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, processor, image_paths_list, text_inputs, base_model, model_name):\n",
        "    \"\"\"\n",
        "    Uses get_image_ranking to generate predictions and confidence scores for a image-list, text-input pairs\n",
        "    \"\"\"\n",
        "    predictions, confidence_scores = [], []\n",
        "\n",
        "    if base_model == \"open_clip\":\n",
        "      tokenizer = open_clip.get_tokenizer(model_name)\n",
        "\n",
        "    for ipaths, text in zip(image_paths_list, text_inputs):\n",
        "        if len(ipaths) == 0:\n",
        "            predictions.append([])\n",
        "            confidence_scores.append([])\n",
        "            continue\n",
        "\n",
        "        # values, indices = get_image_ranking(ipaths, text)\n",
        "        if base_model == \"CLIP\":\n",
        "          values, indices = get_image_ranking_clip(model, processor, ipaths, text)\n",
        "        elif base_model == \"Align\":\n",
        "          values, indices = get_image_ranking_align(model, processor, ipaths, text)\n",
        "        elif base_model == \"open_clip\":\n",
        "          # values, indices = get_image_ranking_open_clip(model, processor, ipaths, text, model_name)\n",
        "          values, indices = openclip_image_ranking(model, processor, tokenizer, ipaths, text)\n",
        "        # elif base_model == \"BLIP\":\n",
        "        #   values, indices = get_image_ranking_blip(model, image_processor, ipaths, text)\n",
        "        else:\n",
        "          raise ValueError(f\"Unknown base_model: {base_model}\")\n",
        "        predictions.append(list(indices.cpu()))\n",
        "        confidence_scores.append(100 * values)\n",
        "\n",
        "    return predictions, confidence_scores\n"
      ],
      "metadata": {
        "id": "0KJzVPW5o-w7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions_multi_text_input(model, processor, image_paths_list, text_inputs, base_model, model_name):\n",
        "    predictions, confidence_scores = [], []\n",
        "\n",
        "    if base_model == \"open_clip\":\n",
        "      tokenizer = open_clip.get_tokenizer(model_name)\n",
        "\n",
        "    for ipaths, text in zip(image_paths_list, text_inputs):\n",
        "        if len(ipaths) == 0:\n",
        "            predictions.append([])\n",
        "            confidence_scores.append([])\n",
        "            continue\n",
        "\n",
        "        # values, indices = get_image_ranking(ipaths, text)\n",
        "        if base_model == \"CLIP\":\n",
        "          values, indices = get_image_ranking_clip_multi_text(model, processor, ipaths, text)\n",
        "        elif base_model == \"Align\":\n",
        "          values, indices = get_image_ranking_align_multi_text(model, processor, ipaths, text)\n",
        "        elif base_model == \"open_clip\":\n",
        "          # values, indices = get_image_ranking_open_clip(model, processor, ipaths, text, model_name)\n",
        "          values, indices = openclip_image_ranking_multi_text(model, processor, tokenizer, ipaths, text)\n",
        "        # elif base_model == \"BLIP\":\n",
        "        #   values, indices = get_image_ranking_blip(model, image_processor, ipaths, text)\n",
        "        else:\n",
        "          raise ValueError(f\"Unknown base_model: {base_model}\")\n",
        "        predictions.append(list(indices.cpu()))\n",
        "        confidence_scores.append(100 * values)\n",
        "\n",
        "    return predictions, confidence_scores\n"
      ],
      "metadata": {
        "id": "b5bgW5VzatDj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "def evaluate_predictions(predictions, df, weights=[0.4, 0.3, 0.2, 0.1, 0.0]):\n",
        "    \"\"\"\n",
        "    Takes predictions, returns three types of evaluation metrics:\n",
        "    - Top-1 Accuracy\n",
        "    - Average Spearman Correlation\n",
        "    - Average Weighted Accuracy\n",
        "    \"\"\"\n",
        "    correct_top1 = 0\n",
        "    spearman_scores, weighted_scores = [], []\n",
        "\n",
        "    for i in range(len(predictions)):\n",
        "        if len(predictions[i]) == 0:\n",
        "            continue\n",
        "\n",
        "        # Ground truth and predictions\n",
        "        pred_order = [df['image_idx_map'].iloc[i][os.path.basename(df['image_paths'].iloc[i][j])] for j in predictions[i]]\n",
        "        ground_truth_order = df['expected_order_indices'].iloc[i]\n",
        "\n",
        "        # Top-1 accuracy\n",
        "        if pred_order[0] == ground_truth_order[0]:\n",
        "            correct_top1 += 1\n",
        "\n",
        "        # Spearman correlation\n",
        "        score, _ = spearmanr(pred_order, ground_truth_order)\n",
        "        spearman_scores.append(score)\n",
        "\n",
        "        # Weighted accuracy\n",
        "        weighted_score = sum(weights[j] for j, img in enumerate(pred_order) if img == ground_truth_order[j])\n",
        "        weighted_scores.append(weighted_score)\n",
        "\n",
        "    return {\n",
        "        \"top1_accuracy\": correct_top1 / len(predictions),\n",
        "        \"average_spearman\": sum(spearman_scores) / len(spearman_scores),\n",
        "        \"average_weighted_accuracy\": sum(weighted_scores) / len(weighted_scores),\n",
        "        \"spearman_scores\": spearman_scores,\n",
        "        \"weighted_scores\": weighted_scores\n",
        "    }\n"
      ],
      "metadata": {
        "id": "EXSAb7fZpGD_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def save_results(experiment_name, base_model, model_name, metrics, results_file=\"experiment_results.csv\"):\n",
        "    \"\"\"\n",
        "    Save experiment results to a CSV file.\n",
        "    \"\"\"\n",
        "    # Add experiment name to metrics\n",
        "    results_row = {\n",
        "        \"base_model\": base_model,\n",
        "        \"model\": model_name,\n",
        "        \"experiment\": experiment_name,\n",
        "        \"top1_accuracy\": metrics[\"top1_accuracy\"],\n",
        "        \"average_spearman\": metrics[\"average_spearman\"],\n",
        "        \"average_weighted_accuracy\": metrics[\"average_weighted_accuracy\"],\n",
        "    }\n",
        "\n",
        "    # Write results to CSV\n",
        "    write_header = not os.path.exists(results_file)\n",
        "    with open(results_file, mode=\"a\", newline=\"\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=results_row.keys())\n",
        "        if write_header:\n",
        "            writer.writeheader()\n",
        "        writer.writerow(results_row)\n",
        "\n",
        "    print(f\"Results saved to {results_file}\")"
      ],
      "metadata": {
        "id": "B4tJMjYjqG_B"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model, processor, df, image_paths, text_inputs, model_name, experiment_name, base_model):\n",
        "    \"\"\"\n",
        "    Run an experiment using transformed embeddings, evaluate metrics, and print results.\n",
        "    \"\"\"\n",
        "    predictions, confidence_scores = get_predictions(model, processor, image_paths, text_inputs, base_model, model_name)\n",
        "    metrics = evaluate_predictions(predictions, df)\n",
        "    save_results(experiment_name, base_model, model_name, metrics)\n",
        "\n",
        "    print(f\"Top-1 Accuracy: {metrics['top1_accuracy'] * 100:.2f}%\")\n",
        "    print(f\"Average Spearman Correlation: {metrics['average_spearman']:.2f}\")\n",
        "    print(f\"Average Weighted Accuracy: {metrics['average_weighted_accuracy']:.2f}\")\n",
        "\n",
        "    return metrics, predictions, confidence_scores"
      ],
      "metadata": {
        "id": "q0ue0qdzK4zo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment_multiple_text_inputs(model, processor, df, image_paths, text_inputs, model_name, experiment_name, base_model):\n",
        "    predictions, confidence_scores = get_predictions_multi_text_input(model, processor, image_paths, text_inputs, base_model, model_name)\n",
        "    metrics = evaluate_predictions(predictions, df)\n",
        "    save_results(experiment_name, base_model, model_name, metrics)\n",
        "\n",
        "    print(f\"Top-1 Accuracy: {metrics['top1_accuracy'] * 100:.2f}%\")\n",
        "    print(f\"Average Spearman Correlation: {metrics['average_spearman']:.2f}\")\n",
        "    print(f\"Average Weighted Accuracy: {metrics['average_weighted_accuracy']:.2f}\")\n",
        "\n",
        "    return metrics, predictions, confidence_scores"
      ],
      "metadata": {
        "id": "wgh_pr1uaRDs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def save_predictions(df, image_paths, predictions, confidence_scores, metrics, prefix, preds_dir='predictions'):\n",
        "    \"\"\"\n",
        "    Save detailed predictions and confidence scores for each example.\n",
        "    \"\"\"\n",
        "    # create 'preds' directory if doesn't exist\n",
        "    if not os.path.exists(preds_dir):\n",
        "        os.makedirs(preds_dir)\n",
        "\n",
        "    # generate output filename\n",
        "    prefix = prefix.strip().replace(\" \", \"_\")\n",
        "    prefix = re.sub(r'[^a-zA-Z0-9_-]', '', prefix)\n",
        "    output_path = f\"{preds_dir}/{prefix}_preds.csv\"\n",
        "\n",
        "    spearman_scores = metrics[\"spearman_scores\"]\n",
        "    weighted_scores = metrics[\"weighted_scores\"]\n",
        "    with open(output_path, mode=\"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"index\", \"compound\", \"ground_truth_order\", \"predicted_order\", \"top1_score\", \"spearman_score\", \"weighted_score\", \"confidence_scores\"])\n",
        "\n",
        "        for i, (pred, conf) in enumerate(zip(predictions, confidence_scores)):\n",
        "            pred_order = [df['image_idx_map'].iloc[i][os.path.basename(image_paths.iloc[i][j])] for j in pred]\n",
        "            ground_truth_order = df[\"expected_order_indices\"].iloc[i]\n",
        "            top1_score = 1 if pred_order[0] == ground_truth_order[0] else 0\n",
        "            spearman_score = round(spearman_scores[i], 3)\n",
        "            weighted_score = round(weighted_scores[i], 3)\n",
        "            formatted_conf_scores = [round(c.item(), 3) for c in conf]\n",
        "            writer.writerow([i, df[\"compound\"].iloc[i], ground_truth_order, pred_order, top1_score, spearman_score, weighted_score, formatted_conf_scores])\n",
        "\n",
        "    print(f\"Predictions saved to {output_path}\")\n"
      ],
      "metadata": {
        "id": "yzhmS1_kqc8F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt GPT & populate data columns"
      ],
      "metadata": {
        "id": "aErtAe0NV-9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPT Prompt 1: NC definition"
      ],
      "metadata": {
        "id": "yPbvQvgBUFsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT Prompt #1\n",
        "\n",
        "import json\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "# initialize openai client with colab secret key\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_PROJECT_KEY'))\n",
        "\n",
        "def generate_paraphrases_batched(compounds, sentence_types):\n",
        "    \"\"\"\n",
        "    Generate paraphrases in batches using GPT-4.\n",
        "    \"\"\"\n",
        "    # Filter out literals since they don't need processing\n",
        "    input_data = [\n",
        "        nc for nc, sentence_type in zip(compounds, sentence_types) if sentence_type != \"literal\"\n",
        "    ]\n",
        "    # Skip batch if all are literal\n",
        "    if not input_data:\n",
        "        return {nc: nc for nc in compounds}  # Return original NCs for all literals\n",
        "\n",
        "    # Create a combined prompt\n",
        "    examples = \"\\n\".join([\n",
        "        f'The idiom is: \"{nc}\".' for nc in input_data\n",
        "    ])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a linguistics expert specializing in idioms. For each of the idioms below, provide a definition that balances accuracy with its emotional and cultural essence.\n",
        "\n",
        "Example:\n",
        "Idiom: \"cold turkey\"\n",
        "Definition: \"Abruptly quitting a habit, marked by discomfort and determination.\"\n",
        "\n",
        "Idioms to define:\n",
        "{examples}\n",
        "\n",
        "Respond in this format:\n",
        "{{\"idioms\": [\n",
        "    {{\"idiom\": \"cold turkey\", \"definition\": \"Abruptly quitting a habit, marked by discomfort and determination.\"}},\n",
        "    {{\"idiom\": \"another idiom\", \"definition\": \"Its definition here.\"}}\n",
        "]}}\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "        )\n",
        "        content = json.loads(response.choices[0].message.content.strip())\n",
        "        results = {item[\"idiom\"]: item[\"definition\"] for item in content[\"idioms\"]}\n",
        "        for idiom, definition in results.items():\n",
        "            print(f\"Idiom: {idiom}\\nDefinition: {definition}\\n\")\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating paraphrases: {e}\")\n",
        "        return {}"
      ],
      "metadata": {
        "id": "MlihCIXK3jn-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to the DataFrame in batches\n",
        "batch_size = 10\n",
        "results = {}\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch = df.iloc[i:i + batch_size]\n",
        "    compounds = batch['compound'].tolist()\n",
        "    sentence_types = batch['sentence_type'].tolist()\n",
        "    batch_results = generate_paraphrases_batched(compounds, sentence_types)\n",
        "    results.update(batch_results)\n",
        "\n",
        "# Map results back to DataFrame\n",
        "df['gpt_prompt_1_resp'] = df['compound'].map(results)\n",
        "\n",
        "# For rows with null 'paraphrased_nc', set equal to 'compound'\n",
        "df['gpt_prompt_1_resp'].fillna(df['compound'], inplace=True)"
      ],
      "metadata": {
        "id": "F-cpXwfz3o93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e24b759-6edc-4c83-f78d-ca9f6e23970d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Idiom: elbow grease\n",
            "Definition: Hard physical work, especially vigorous cleaning, characterized by personal effort and perseverance.\n",
            "\n",
            "Idiom: night owl\n",
            "Definition: A person habitually active or awake at night, often associated with creativity or solitude.\n",
            "\n",
            "Idiom: heart of gold\n",
            "Definition: Incredibly kind and generous nature, reflecting a person's ability to be compassionate and unselfish.\n",
            "\n",
            "Idiom: agony aunt\n",
            "Definition: A person, often a columnist, who gives advice to people with personal problems, embodying sensitivity and wisdom.\n",
            "\n",
            "Idiom: shrinking violet\n",
            "Definition: A person who is shy or modest and avoids drawing attention to themselves, often associated with introversion or lack of confidence.\n",
            "\n",
            "Idiom: banana republic\n",
            "Definition: A small nation, especially in the tropics, dependent on one crop or the influx of foreign capital, often associated with instability, corruption, and inequality.\n",
            "\n",
            "Idiom: private eye\n",
            "Definition: A private investigator, often operating outside law enforcement, symbolizing an individual's pursuit of truth and justice.\n",
            "\n",
            "Idiom: cold turkey\n",
            "Definition: Abruptly quitting a habit, marked by discomfort and determination.\n",
            "\n",
            "Idiom: pipe dream\n",
            "Definition: A wish or idea that is unrealistic or fanciful, often marked by an element of hope and disappointment.\n",
            "\n",
            "Idiom: rocket science\n",
            "Definition: An activity or concept that is very complex or difficult to understand, often used humorously to overstate the complexity of mundane tasks.\n",
            "\n",
            "Idiom: nest egg\n",
            "Definition: A sum of money saved for the future, often with a sense of security and foresight.\n",
            "\n",
            "Idiom: bull market\n",
            "Definition: A period of rising stock prices, often associated with optimism and investor confidence.\n",
            "\n",
            "Idiom: beached whale\n",
            "Definition: A person or thing that is out of place or in a situation where they do not fit in, often used humorously or self-deprecatingly.\n",
            "\n",
            "Idiom: cold turkey\n",
            "Definition: Abruptly quitting a habit, marked by discomfort and determination.\n",
            "\n",
            "Idiom: lounge lizard\n",
            "Definition: A person, typically a man, who spends a lot of time in social settings, often in order to seduce others.\n",
            "\n",
            "Idiom: bear market\n",
            "Definition: A market situation in which prices are falling, creating a sense of pessimism and caution among investors.\n",
            "\n",
            "Idiom: white hat\n",
            "Definition: In the context of cybersecurity, a person who hacks into systems to find and fix vulnerabilities, serving a noble and protective role.\n",
            "\n",
            "Idiom: cold turkey\n",
            "Definition: Abruptly quitting a habit, marked by discomfort and determination.\n",
            "\n",
            "Idiom: smoking gun\n",
            "Definition: Irrefutable evidence that proves guilt or wrongdoing, suggestive of a dramatic disclosure.\n",
            "\n",
            "Idiom: old flame\n",
            "Definition: A former romantic partner, whose memory often evokes nostalgia and longing.\n",
            "\n",
            "Idiom: ivory tower\n",
            "Definition: A place or state of privileged seclusion, often related to academic or artistic pursuits, disconnected from practical realities.\n",
            "\n",
            "Idiom: black sheep\n",
            "Definition: An individual who differs significantly from their family or group, often viewed with disapproval or as an outcast.\n",
            "\n",
            "Idiom: gravy train\n",
            "Definition: A highly lucrative and relatively easy way of earning money, often seen as undeserved or unethical.\n",
            "\n",
            "Idiom: rat race\n",
            "Definition: A competitive struggle for success or survival within a structured environment, often characterized by stress and endless pursuit of material wealth.\n",
            "\n",
            "Idiom: spring chicken\n",
            "Definition: Used to represent someone young, energetic, often naive, among a group of significantly older or experienced persons.\n",
            "\n",
            "Idiom: inner circle\n",
            "Definition: A small, intimate, and influential group of people who share interests and confidences, and exert control over a larger group. This idiom reflects exclusivity and power dynamics.\n",
            "\n",
            "Idiom: bad apple\n",
            "Definition: One person within a group who, because of their negative behaviour, influences or spoils the entire group. This idiom underscores the impact of individual influence.\n",
            "\n",
            "Idiom: honey trap\n",
            "Definition: A strategic scenario where an attractive person lures another into revealing important information or into a compromising situation, underscoreing manipulation by appeal.\n",
            "\n",
            "Idiom: open book\n",
            "Definition: An individual or situation that is easy to understand or discern, indicative of transparency.\n",
            "\n",
            "Idiom: baby blues\n",
            "Definition: Mild depression, sadness, or worry typically experienced shortly after childbirth, infused with tender concern and vulnerability.\n",
            "\n",
            "Idiom: brain surgery\n",
            "Definition: A task, issue, or problem that is highly complex or difficult, often requiring intricate precision or knowledge.\n",
            "\n",
            "Idiom: red flag\n",
            "Definition: An indication or warning of a problem, danger, or impending disaster, demanding immediate attention and reaction.\n",
            "\n",
            "Idiom: white elephant\n",
            "Definition: A possession which its owner cannot dispose of and whose cost (particularly cost of upkeep) is out of proportion to its usefulness or worth, colored by frustration and regret.\n",
            "\n",
            "Idiom: rat run\n",
            "Definition: A minor, often residential street used by drivers during heavy traffic to bypass main roads, connotating opportunism and evasion.\n",
            "\n",
            "Idiom: graveyard shift\n",
            "Definition: A work shift running through the late hours of the night until early morning, carrying undertones of endurance and isolation.\n",
            "\n",
            "Idiom: dirty money\n",
            "Definition: Wealth obtained through illegal or unethical actions, stained by guilt and secrecy.\n",
            "\n",
            "Idiom: high life\n",
            "Definition: Living in luxury and indulgence, often showcasing wealth and status.\n",
            "\n",
            "Idiom: guinea pig\n",
            "Definition: Someone or something used in a test or experiment, echoing the vulnerability of being a test subject.\n",
            "\n",
            "Idiom: cat's eyes\n",
            "Definition: Witnessing or observing discreetly, invoking the stealth and sharp observation of a cat.\n",
            "\n",
            "Idiom: low-hanging fruit\n",
            "Definition: Easily achievable tasks or goals, reflecting the simple effort it takes to pick fruit hanging low on a tree.\n",
            "\n",
            "Idiom: busy bee\n",
            "Definition: An individual who is hardworking and consistently active, reflecting the industrious nature of a bee.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-36673918767d>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['gpt_prompt_1_resp'].fillna(df['compound'], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPT Prompt 2: NC definition with multi-step reasoning"
      ],
      "metadata": {
        "id": "LKjGmZARTLs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT Prompt #2\n",
        "\n",
        "import json\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "# initialize openai client with colab secret key\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_PROJECT_KEY'))\n",
        "\n",
        "def generate_paraphrases_batched_2(compounds, sentence_types):\n",
        "    \"\"\"\n",
        "    Generate paraphrases in batches using GPT-4.\n",
        "    \"\"\"\n",
        "    # Filter out literals since they don't need processing\n",
        "    input_data = [\n",
        "        nc for nc, sentence_type in zip(compounds, sentence_types) if sentence_type != \"literal\"\n",
        "    ]\n",
        "    # Skip batch if all are literal\n",
        "    if not input_data:\n",
        "        return {nc: nc for nc in compounds}  # Return original NCs for all literals\n",
        "\n",
        "    # Create a combined prompt\n",
        "    examples = \"\\n\".join([\n",
        "        f'The idiom is: \"{nc}\".' for nc in input_data\n",
        "    ])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a linguistics expert specializing in idioms. For each of the idioms below, do the following steps aloud (in writing):\n",
        "1. Give a verbose explanation of the idiom, including what connotations it carries or undertones it evokes.\n",
        "2. List three potential definitions, no longer than 20 words each, that capture the essence of the phrase in a general manner.\n",
        "3. Choose the best definition.\n",
        "\n",
        "Example #1:\n",
        "Idiom: \"cold turkey\"\n",
        "Definition: \"Abruptly quitting a habit or addiction, overcoming discomfort or pain, requiring determination.\"\n",
        "\n",
        "Example #2:\n",
        "Idiom: \"piece of cake\"\n",
        "Definition: \"Easy, simple to accomplish, requiring little effort, not a problem.\"\n",
        "\n",
        "Idioms to define:\n",
        "{examples}\n",
        "\n",
        "Respond in this format:\n",
        "{{\"idioms\": [\n",
        "    {{\"idiom\": \"cold turkey\", \"verbose_definition\": \"<verbose_definition>\", \"possible_definitions\": \"<three possible definitions>\", \"definition\": \"Abruptly quitting a habit, marked by discomfort and determination.\"}},\n",
        "    {{\"idiom\": \"<another idiom>\", \"verbose_definition\": \"<verbose_definition>\", \"possible_definitions\": \"<three possible definitions>\" , \"definition\": \"<its definition>\" }}\n",
        "]}}\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "        )\n",
        "        content = json.loads(response.choices[0].message.content.strip())\n",
        "        results = {item[\"idiom\"]: item[\"definition\"] for item in content[\"idioms\"]}\n",
        "        for item in content[\"idioms\"]:\n",
        "            print(f\"Idiom: {item['idiom']}\\nVerbose: {item['verbose_definition']}\\nPossible: {item['possible_definitions']}\\nDefinition: {item['definition']}\\n\")\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating paraphrases: {e}\")\n",
        "        return {}"
      ],
      "metadata": {
        "id": "SapRs6r8Xe3d"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to the DataFrame in batches\n",
        "batch_size = 10\n",
        "results = {}\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch = df.iloc[i:i + batch_size]\n",
        "    compounds = batch['compound'].tolist()\n",
        "    sentence_types = batch['sentence_type'].tolist()\n",
        "    batch_results = generate_paraphrases_batched_2(compounds, sentence_types)\n",
        "    results.update(batch_results)\n",
        "\n",
        "# Map results back to DataFrame\n",
        "df['gpt_prompt_2_resp'] = df['compound'].map(results)\n",
        "\n",
        "# For rows with null 'paraphrased_nc', set equal to 'compound'\n",
        "df['gpt_prompt_2_resp'].fillna(df['compound'], inplace=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kb5mivD2aMD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8af9af-7392-416b-b763-b4963a14fe54"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Idiom: elbow grease\n",
            "Verbose: Hard work and determination applied to a menial or difficult task, often referring to a physically demanding one. The idiom evokes the image of putting in extra effort or exertion.\n",
            "Possible: ['Applying hard work and commitment.', 'Effort used in scrubbing or cleaning.', 'Physical exertion done determinedly.']\n",
            "Definition: Applying hard work and commitment.\n",
            "\n",
            "Idiom: night owl\n",
            "Verbose: Refers to a person who is naturally most alert, productive, or creative during the night or late hours. The phrase evokes the nocturnal habits of the owl.\n",
            "Possible: ['Individual who stays up late.', 'Person preferring late hours for productivity.', 'Someone active during night-time.']\n",
            "Definition: Person preferring late hours for productivity.\n",
            "\n",
            "Idiom: heart of gold\n",
            "Verbose: Describes someone who is genuinely kind, compassionate, or selfless, much like the way gold is valued for its worth. This idiom suggests selflessness and moral worth.\n",
            "Possible: ['Being kind and generous.', 'Characterized by selflessness or compassion.', 'Genuinely good-natured.']\n",
            "Definition: Being kind and generous.\n",
            "\n",
            "Idiom: agony aunt\n",
            "Verbose: Refers to a person, often a woman, providing advice or listening empathetically to other people's problems. Traditionally, it's connected to advice columns in newspapers or magazines.\n",
            "Possible: ['Person who offers advice or solutions.', 'Advice columnist in media.', \"Listener and advisor for others' problems.\"]\n",
            "Definition: Person who offers advice or solutions.\n",
            "\n",
            "Idiom: shrinking violet\n",
            "Verbose: This idiom refers to a person who is excessively shy, introverted, or who avoids drawing attention to themselves. The term brings to mind the image of a delicate violet flower retracting its petals.\n",
            "Possible: ['Excessively shy individual.', 'Person avoiding attention or spotlight.', 'Introverted or timid person.']\n",
            "Definition: Excessively shy individual.\n",
            "\n",
            "Idiom: banana republic\n",
            "Verbose: A pejorative term for a small country that is politically unstable and whose economy is dominated by foreign companies. Originating from the exploitation of Central American countries by banana companies.\n",
            "Possible: ['Politically unstable small country.', 'Country dependent on foreign corporations.', 'State exploited by foreign companies.']\n",
            "Definition: Politically unstable small country.\n",
            "\n",
            "Idiom: private eye\n",
            "Verbose: Refers to a private investigator or a detective who is not part of a police force. It's associated with the traditional image of a sleuth or detective.\n",
            "Possible: ['Private detective or investigator.', 'Non-police detective.', 'Independent investigator.']\n",
            "Definition: Private detective or investigator.\n",
            "\n",
            "Idiom: pipe dream\n",
            "Verbose: A pipe dream is an aspiration or goal that is perceived as unrealistically optimistic or fanciful. The idiom derives from the 19th century when opium smokers would have vivid hallucinations, thus their dreams or ambitions while under the influence were known as 'pipe dreams.' It often has a connotation of delusion or naivety.\n",
            "Possible: ['Unrealistic or fanciful goal', 'Unattainable desire or aspiration', 'Dream that is unlikely to be fulfilled']\n",
            "Definition: Unrealistic or fanciful goal.\n",
            "\n",
            "Idiom: rocket science\n",
            "Verbose: The term 'rocket science' is used metaphorically to suggest something requiring great intelligence or technical know-how. It draws allusion from the actual field of rocket science, which involves complex principles of physics and engineering. Hence, it implies a task or concept being highly difficult or overly complicated.\n",
            "Possible: ['Extremely difficult task', 'Concept requiring high intelligence', 'Overly complicated idea']\n",
            "Definition: Extremely difficult task.\n",
            "\n",
            "Idiom: nest egg\n",
            "Verbose: The term 'nest egg' originates from the practice of leaving an egg in a nest to encourage a hen to continue laying. Figuratively, it refers to a sum of money saved for the future, typically for retirement. It carries the undertones of prudence, patience, and long-term planning.\n",
            "Possible: ['Retirement savings', 'Money saved for future use', 'Funds accumulated for security']\n",
            "Definition: Money saved for future use.\n",
            "\n",
            "Idiom: bull market\n",
            "Verbose: The term 'bull market' is from financial jargon, it refers to a market scenario where prices are expected to rise or are rising, providing an opportunity for investors to buy. The bull symbolizes charging ahead with force, suggesting the aggressive and optimistic nature of such a market condition.\n",
            "Possible: ['Market with rising prices', 'Favorable investment condition', 'Economic situation indicating growth']\n",
            "Definition: Market with rising prices.\n",
            "\n",
            "Idiom: beached whale\n",
            "Verbose: A 'beached whale' is a term used metaphorically to refer to someone or something that is out of place or in a situation where it doesn't belong. Just as a whale stranded on a beach is in a dire circumstance, the term carries connotations of discomfort, helplessness, or conspicuousness.\n",
            "Possible: ['Someone out of place', 'Thing in an unsuitable situation', 'Figuratively stranded']\n",
            "Definition: Someone out of place.\n",
            "\n",
            "Idiom: lounge lizard\n",
            "Verbose: The term 'lounge lizard' is often used pejoratively to describe a man who frequents public venues, such as nightclubs or bars, with the intention of seducing women. The idiom carries connotations of insincerity, manipulation, and predatory behaviour. It may evoke an image of a man who is not sincerely interested in genuine relationships with women, but instead seeks to charm them for his own benefit.\n",
            "Possible: ['A man who hangs out in public venues aiming to charm women', 'An insincere man seducing women in clubs or bars', 'A man frequenting nightspots to woo women insincerely']\n",
            "Definition: An insincere man seducing women in clubs or bars.\n",
            "\n",
            "Idiom: bear market\n",
            "Verbose: A 'bear market' is a term used in the financial world to describe a situation in which the prices of securities are falling, and widespread pessimism causes the negative sentiment to be self-sustaining. It is often associated with a slowdown in the economy and is characterized by investors' lack of confidence. The bear, seen as a creature that moves slowly and cautiously, is used as a symbol for such market conditions.\n",
            "Possible: ['A financial market with falling prices', 'An economic period of pessimism and declining securities value', 'A state in trading where stock prices fall over an extended time']\n",
            "Definition: A financial market with falling prices.\n",
            "\n",
            "Idiom: white hat\n",
            "Verbose: The idiom 'white hat' originates from Western movies where heroes would wear white cowboy hats, in contrast to villains who wore black ones. In the world of cyber security, a 'white hat' is a hacker who uses their skills for good by helping to discover and fix security vulnerabilities. This idiom carries positive connotations of helpfulness, ethical behavior, and working within the law to improve security.\n",
            "Possible: ['A hacker who improves security systems', 'An ethical hacker working for good purposes', 'Positive and helpful cybersecurity expert']\n",
            "Definition: An ethical hacker working for good purposes.\n",
            "\n",
            "Idiom: smoking gun\n",
            "Verbose: This idiom originated in the context of a smoking firearm, acting as a surefire piece of evidence or clue that indicates guilt in a crime investigation. It has evolved to represent any form of irrefutable proof or clear demonstration of allegation\n",
            "Possible: ['Strong, undeniable proof', 'Clear evidence of guilt', 'Indisputable indication of a crime']\n",
            "Definition: Clear evidence of guilt.\n",
            "\n",
            "Idiom: old flame\n",
            "Verbose: The metaphor 'old flame' may elicit vivid visuals of a once-bright, passionate fire that has since faded but can be reignited. It is a nostalgic term used to denote a former lover, someone with whom the speaker had a significant romantic relationship\n",
            "Possible: ['A previous romantic partner', 'An individual once in a meaningful loving relationship', 'Former love interest']\n",
            "Definition: A previous romantic partner.\n",
            "\n",
            "Idiom: ivory tower\n",
            "Verbose: The 'ivory tower' signifies a privileged, sometimes disconnected, state of being, often related to academia or scholars who are seemingly detached from real-world issues. It is a place identified as being removed from the practical world, filled with metaphorically lofty and detached intellectuals\n",
            "Possible: ['An isolated place of intellectualism', 'State of being disconnected from practical realities', 'Refuge of the privileged, often removed from the worldly troubles']\n",
            "Definition: State of being disconnected from practical realities.\n",
            "\n",
            "Idiom: black sheep\n",
            "Verbose: In 'black sheep', the color black is used to indicate difference or deviance, while sheep is a common symbol for a group or flock. Thus, a black sheep is someone who noticeably doesn't fit into their family or group due to their unconventional behavior or habits\n",
            "Possible: ['An outcast within a group', 'Someone who stands out due to differences', \"A person who doesn't conform to the expectations\"]\n",
            "Definition: An outcast within a group.\n",
            "\n",
            "Idiom: gravy train\n",
            "Verbose: The 'gravy train' essentially describes a situation or occupation where one can make substantial amounts of money with little effort. The phrase evokes undertones of windfall bonuses, luxurious livelihoods, and easy wealth\n",
            "Possible: ['Source of easy money', 'Profitable endeavour involving minimal effort', 'Situation that leads to substantial financial gain']\n",
            "Definition: Source of easy money.\n",
            "\n",
            "Idiom: rat race\n",
            "Verbose: The 'rat race' is often visualized as a circle of rats endlessly chasing something, reminiscent of the daily grind in human lives. It commonly refers to the endless, self-defeating and unrewarding pursuit of wealth or higher societal position\n",
            "Possible: ['Endless, frustrating pursuit for success', 'Futile chase for material wealth', 'Non-stop but unrewarding struggle for progress']\n",
            "Definition: Endless, frustrating pursuit for success.\n",
            "\n",
            "Idiom: spring chicken\n",
            "Verbose: The idiom 'spring chicken' refers to a person who is young and in good health. The term originates from the preference for young, spring-born chickens which are more tender than older ones. By extension, it is often used in a slightly ironic or humorous way to refer to somebody who is not as young as they once were.\n",
            "Possible: ['A person who is youthful and vigorous', 'Someone who is immature due to their youth', 'An individual in their prime years of life']\n",
            "Definition: A person who is youthful and vigorous\n",
            "\n",
            "Idiom: inner circle\n",
            "Verbose: The 'inner circle' refers to an exclusive group of people in a society or organization who hold power and influence, often close to a central figure of authority. Membership in this group typically signifies trust, confidence, and privileged status. The feelings evoked by this idiom can include exclusivity, power, secrecy and influence.\n",
            "Possible: ['A select group of influential individuals', 'Confidants or close associates of a person', 'Influential people with privileged access to information']\n",
            "Definition: A select group of influential individuals\n",
            "\n",
            "Idiom: bad apple\n",
            "Verbose: A 'bad apple' is an idiom describing a person who negatively influences others within a group, or an individual known for their bad behavior or poor character. It evokes the old adage: 'one bad apple spoils the barrel' suggesting that the negatives can often overshadow the positives, thus can bring down the morale of the entire group.\n",
            "Possible: ['A troublesome person within a group', 'An individual with bad character or behavior', 'A person causing issues within a larger community']\n",
            "Definition: An individual with bad character or behavior\n",
            "\n",
            "Idiom: honey trap\n",
            "Verbose: A 'honey trap' is an idiom that denotes a strategic encounter designed to deceive or trap someone, often using temptations appealing to their personal instincts. Typically found in the context of espionage, it implies seduction for manipulation or betrayal. The undertones of the phrase are associated with deceit, manipulation, and betrayal.\n",
            "Possible: ['A deceptive act designed to trap or ensnare', 'Seductive bait in a strategic scheme', 'Allure used to deceive or lead astray']\n",
            "Definition: A deceptive act designed to trap or ensnare\n",
            "\n",
            "Idiom: open book\n",
            "Verbose: The idiom 'open book' is often used to describe a person who is easy to understand or read. They usually lack secrecy or hidden aspects in their character, emotions or thoughts. They are candid, straightforward, and hide nothing, just like an open book where every detail is displayed evidently.\n",
            "Possible: ['Someone who is straightforward', 'A person with no secrets', 'An uncomplicated individual']\n",
            "Definition: A person who is easy to understand or read, without secrecy or hidden aspects.\n",
            "\n",
            "Idiom: baby blues\n",
            "Verbose: The idiom 'baby blues' typically refers to a state of mild, transient emotional distress experienced by new mothers in the days following childbirth due to hormonal changes and physical exhaustion. In a broader context, it can also depict sadness or depression.\n",
            "Possible: ['Emotional distress after childbirth', 'State of mild depression', 'Temporary sadness in new mothers']\n",
            "Definition: Mild, transient emotional distress experienced by new mothers after childbirth.\n",
            "\n",
            "Idiom: brain surgery\n",
            "Verbose: The idiom 'brain surgery' is often used to emphasize the extreme difficulty or complexity of a task. The phrase derives from the actual profession which requires high skill and knowledge, and is thus metaphorically used to denote any situation that's complex or challenging.\n",
            "Possible: ['A very difficult task', 'Complicated procedure', 'Task requiring great skill']\n",
            "Definition: A task or situation that is extremely complex or difficult.\n",
            "\n",
            "Idiom: red flag\n",
            "Verbose: The idiom 'red flag' traditionally symbolizes danger or a warning sign. It's used as a metaphor to indicate potential problems or trouble that require attention. It is often linked with situations where caution should be exercised.\n",
            "Possible: ['A warning sign', 'Indicator of a problem', 'Sign of danger or trouble']\n",
            "Definition: A warning sign indicating potential problems or trouble.\n",
            "\n",
            "Idiom: white elephant\n",
            "Verbose: A 'white elephant' is a phrase that describes something that is costly and hard to maintain but is also difficult to get rid of. It comes from historical practices where kings used to gift a white elephant, a burdensome yet sacred creature, which was expensive to sustain.\n",
            "Possible: ['A burdensome possession', 'Expensive item that is hard to dispose of', 'Costly and inconvenient asset']\n",
            "Definition: An expensive and burdensome possession that's hard to get rid of.\n",
            "\n",
            "Idiom: rat run\n",
            "Verbose: The term 'rat run' refers to a minor, often residential street used by drivers during peak periods to avoid traffic on main roads. It gives the notion of scurrying rats in a maze, ensuring a quick escape route from one place to another.\n",
            "Possible: ['Shortcut through minor streets', 'Alternative route to avoid traffic', 'A quick, less crowded driving path']\n",
            "Definition: A minor, often residential, street used as a shortcut to avoid traffic.\n",
            "\n",
            "Idiom: graveyard shift\n",
            "Verbose: The phrase 'graveyard shift' is used to denote late night or overnight shift work. Often associated with jobs that require workers to stay active during the night hours, it evokes a sense of loneliness and eeriness typically associated with graveyards at night.\n",
            "Possible: ['Overnight work schedule', 'Working during the late night hours', 'Night shift work']\n",
            "Definition: Late night or overnight shift work.\n",
            "\n",
            "Idiom: dirty money\n",
            "Verbose: The idiom 'dirty money' refers to currency or wealth that has been obtained in unethical or illegal ways, evoking the immorality and guilt associated with such gains.\n",
            "Possible: ['Money obtained through illegal or immoral activities', 'Illicitly earned funds', 'Unethically gained wealth']\n",
            "Definition: Money obtained through illegal or immoral activities.\n",
            "\n",
            "Idiom: high life\n",
            "Verbose: The phrase 'high life' refers to a luxurious or extravagant lifestyle, often associated with wealth, indulgence, and leisure.\n",
            "Possible: ['Living luxuriously and extravagantly', 'Affluent, indulgent lifestyle', 'Wealthy and extravagant way of living']\n",
            "Definition: Living luxuriously and extravagantly.\n",
            "\n",
            "Idiom: guinea pig\n",
            "Verbose: The term 'guinea pig' refers to anyone used as a subject for experimentation or testing. It implies a situation where there could be risks or unknown outcomes for the person involved.\n",
            "Possible: ['Individual used for testing', 'Subject of an experiment', \"One who undergoes trials for others' benefit\"]\n",
            "Definition: Individual used for testing.\n",
            "\n",
            "Idiom: cat's eyes\n",
            "Verbose: The idiom 'cat's eyes' usually refers to the reflective road safety devices found on many highways. It can also refer to a watchful, sharp gaze.\n",
            "Possible: ['Road safety reflectors', 'Intensely watchful gaze', 'Sharp, observant eyes']\n",
            "Definition: Road safety reflectors or an intensely watchful gaze.\n",
            "\n",
            "Idiom: low-hanging fruit\n",
            "Verbose: The term 'low-hanging fruit' typically refers to tasks, goals, or objectives that can be achieved with minimal effort or difficulty. It implies an opportunity for easy gains or progress.\n",
            "Possible: ['Easy-to-reach goals or targets', 'Tasks that require minimal effort', 'Readily achievable objectives']\n",
            "Definition: Easy-to-reach goals or targets.\n",
            "\n",
            "Idiom: busy bee\n",
            "Verbose: The idiom 'busy bee' is a metaphorical phrase used to describe someone who is energetic and hardworking, often constantly busy or always involved in numerous activities. It carries a positive connotation and suggests industriousness and diligence.\n",
            "Possible: ['Person who is very active and industrious', 'Hardworking, energetic individual', 'Someone constantly busy with activities']\n",
            "Definition: Person who is very active and industrious.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-837785a48e1d>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['gpt_prompt_2_resp'].fillna(df['compound'], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### variant - Jude"
      ],
      "metadata": {
        "id": "5DjXnXrGt_YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT Prompt #4\n",
        "\n",
        "import json\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "# initialize openai client with colab secret key\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_PROJECT_KEY'))\n",
        "\n",
        "def generate_paraphrases_4(compound, sentence):\n",
        "    \"\"\"\n",
        "    Generate paraphrases using GPT-4.\n",
        "    \"\"\"\n",
        "    # Create a combined prompt\n",
        "    # examples = \"\\n\".join([\n",
        "    #     f'Phrase: \"{nc}\"\\nSentence: \"{sent}\"\\n' for nc, sent in zip(compounds, sentences)\n",
        "    # ])\n",
        "    prompt = f\"\"\"You are a linguistics expert specializing in idioms. Given a potentially idiomatic phrase, and a sentence containing that phrase, you should determine whether the phrase is used literally or idiomatically in this particular instance, and describe the meaning of the phrase in this context.\n",
        "Explain your reasoning.\n",
        "\n",
        "Example #1\n",
        "Phrase: \"kick the bucket\"\n",
        "Sentence: \"As John stood up from the table he accidentally kicked the bucket that was hidden underneath it.\"\n",
        "Reasoning: To kick is to strike with the foot. A bucket is a container made of metal or plastic for carrying water. Kicking a bucket therefore means striking a container with the foot.\n",
        "Alternatively, to kick the bucket, when used idiomatically, can mean to die.\n",
        "Which option makes more sense in this case?\n",
        "In the literal case, the sentence would mean that John is kicking a physical object, which we are told is underneath the table. It is plausible that a bucket could be hidden underneath a table and that standing up would cause one to kick that bucket.\n",
        "In the idiomatic case, the sentence would mean that John accidentally dies as he stands up from the table, but then what is hidden underneath the table? The action of dying cannot be underneath a table. This usage does not make sense.\n",
        "Therefore, the phrase is used literally in this instance.\n",
        "Example 1 response: {{\"phrase\": \"kick the bucket\", \"usage\": \"literal\", \"meaning\": \"kicking a bucket, which might cause pain in the foot or cause a loud noise.\"}}\n",
        "\n",
        "\n",
        "Example #2\n",
        "Idiom: \"piece of cake\"\n",
        "Sentence: \"Sarah thought the final exam was a piece of cake compared to the midterm.\"\n",
        "Reasoning: A cake is a baked dessert, a piece of cake is a small amount of desert.\n",
        "Alternatively, in idiomatic usage, something is considered a piece of cake if it is easy or requires little effort.\n",
        "Which option makes more sense in this case?\n",
        "In the literal case, the sentence would mean that Sarah thinks her exam is a piece of dessert. The piece of cake is compared to a different exam. It is unlikely that an exam is literally a piece of cake, and cake is not a comparable value like distance or size or intensity. This usage is unlikely.\n",
        "In the idiomatic case, the sentence would mean that Sarah thinks her final exam was easy compared to the midterm. It is common to compare one exam with another in terms of its difficulty, so this usage makes sense.\n",
        "Therefore, the phrase is used idiomatically in this instance.\n",
        "Example 2 response: {{\"phrase\": \"piece of cake\", \"usage\": \"idiomatic\", \"meaning\": \"an activity or task that is delightfully easy, requiring little effort and quickly accomplished.\"}}\n",
        "\n",
        "\n",
        "Example #3\n",
        "Phrase: \"{compound}\"\n",
        "Sentence: \"{sentence}\"\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "        )\n",
        "        pos = response.choices[0].message.content.strip().find('Example 3 response')\n",
        "        json_response = response.choices[0].message.content.strip()[pos+19:]\n",
        "        content = json.loads(json_response)\n",
        "        print(f\"Idiom: {content['phrase']}\\nMeaning: {content['meaning']}\\nUsage: {content['usage']}\")\n",
        "        return content\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating paraphrases: {e}\")\n",
        "        return {}"
      ],
      "metadata": {
        "id": "a56QgBTbt-XH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []"
      ],
      "metadata": {
        "id": "HjKoD4YLKBjJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_results = results"
      ],
      "metadata": {
        "id": "LkFG4b58NqGI"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gpt_prompt_4_results.csv', mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    fieldnames = results[0].keys()\n",
        "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(results)"
      ],
      "metadata": {
        "id": "rlrANORSPt2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to the DataFrame in batches\n",
        "\n",
        "for i in range(len(df)):\n",
        "    batch = df.iloc[i]\n",
        "    compound = batch['compound']\n",
        "    sentence = batch['sentence']\n",
        "    batch_results = generate_paraphrases_4(compound, sentence)\n",
        "    results.append(batch_results)\n",
        "\n",
        "# # Map results back to DataFrame\n",
        "# df['gpt_prompt_4_resp'] = df['compound'].map(results)\n",
        "\n",
        "# # For rows with null 'paraphrased_nc', set equal to 'compound'\n",
        "# df['gpt_prompt_4_resp'].fillna(df['compound'], inplace=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SRqimI_Mt-Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['gpt_prompt_4_resp'] = [res['meaning'] for res in results]\n",
        "df['gpt_prompt_4_type'] = [res['usage'] for res in results]\n",
        "\n",
        "# # For rows with null 'paraphrased_nc', set equal to 'compound'\n",
        "# df['gpt_prompt_4_resp'].fillna(df['compound'], inplace=True)"
      ],
      "metadata": {
        "id": "SFvlCZxEOXTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['gpt_prompt_4_correct_type'] = df['gpt_prompt_4_type'] == df['sentence_type']"
      ],
      "metadata": {
        "id": "9SQZtsgYO0mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['gpt_prompt_4_correct_type'].sum()"
      ],
      "metadata": {
        "id": "bOrzDNFLO6iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "65/70"
      ],
      "metadata": {
        "id": "62BptTDdPGgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPT Prompt 3: NC in-context definition, prompt decomposition (subtasks)"
      ],
      "metadata": {
        "id": "uZgJsl5kTP6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT Prompt #3\n",
        "\n",
        "import json\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "# initialize openai client with colab secret key\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_PROJECT_KEY'))\n",
        "\n",
        "def generate_paraphrases_batched_3(compounds, sentences):\n",
        "    \"\"\"\n",
        "    Generate paraphrases in batches using GPT-4.\n",
        "    \"\"\"\n",
        "    # Create a combined prompt\n",
        "    examples = \"\\n\\n\".join([\n",
        "        f'Phrase: \"{nc}\"\\nSentence: \"{sentence}\"' for nc, sentence in zip(compounds, sentences)\n",
        "    ])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a linguistics expert specializing in figurative language. You will be given a set samples, each containing a potentially figurative English phrase paired with a sentence that said phrase is used in.\n",
        "For each sample, you are to do the following:\n",
        "1. Read the sentence; consider how the phrase is used in the sentence. It might be used figuratively (i.e. as an idiom), and it might be used literally (i.e. word composition).\n",
        "2. Verbose explanation: Given your familiarity with the phrase's possible meanings, and having considered how it's used in the sentence, give a verbose explanation of what the phrase means in the context of the sentence. This can be a few sentences long.\n",
        "3. Determine usage: State whether the phrase is used figuratively or literally in the sentence.\n",
        "4. Definition: A concise, generalized definition of the phrase in this sentence.\n",
        "5. Other usage definition: Assuming the phrase has both a literal definition and a figurative definition, give the definition for the OTHER usage.\n",
        "\n",
        "Example #1:\n",
        "<Sample>\n",
        "Phrase: \"cold turkey\"\n",
        "Sentence: \"John quit smoking cold turkey and never looked back, not that it was easy.\"\n",
        "---\n",
        "<Output>\n",
        "#3 - \"Figuratively\"\n",
        "#4 - \"Abruptly quitting a habit, marked by discomfort and determination\"\n",
        "#5 - \"A turkey, which is a type of bird, that is cold\"\n",
        "\n",
        "Example #2:\n",
        "<Sample>\n",
        "Phrase: \"piece of cake\"\n",
        "Sentence: \"The boy eyed the piece of cake from afar as the waitress approached from across the room.\"\n",
        "---\n",
        "<Output>\n",
        "#3 - \"Literally\"\n",
        "#4 - \"A slice of a sweet, baked dessert\"\n",
        "#5 - \"A task that can be completed with no difficulty; something easy to accomplish\"\n",
        "\n",
        "Respond in this format:\n",
        "{{\"samples\": [\n",
        "    {{\"phrase\": \"cold turkey\", \"verbose_definition\": \"<see #2 above>\", \"usage\": \"<see #3 above>\", \"definition\": \"<see #4 above>\", \"other_definition\": \"<see #5 above>\"}},\n",
        "    {{\"phrase\": \"piece of cake\", \"verbose_definition\": \"<see #2 above>\", \"usage\": \"<see #3 above>\", \"definition\": \"<see #4 above>\", \"other_definition\": \"<see #5 above>\" }}\n",
        "]}}\n",
        "\n",
        "In your definitions, do not preface your definition with phrases like, \"The literal meaning would be...\" or \"The figurative meaning is...\". Just give the definition, such that it could be used in a downstream task.\n",
        "These are the samples:\n",
        "{examples}\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "        )\n",
        "        content = json.loads(response.choices[0].message.content.strip())\n",
        "        print(json.dumps(content, indent=4))\n",
        "        results = {item[\"phrase\"]: item[\"definition\"] for item in content[\"samples\"]}\n",
        "        # for item in content[\"samples\"]:\n",
        "        #     print(f\"Phrase: {item['phrase']}\\nVerbose: {item['verbose_definition']}\\nUsage: {item['usage']}\\nDefinition: {item['definition']}\\nOther Definition: {item['other_definition']}\")\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating paraphrases: {e}\")\n",
        "        return {}"
      ],
      "metadata": {
        "id": "yGmwiwOtfXOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to the DataFrame in batches\n",
        "batch_size = 5\n",
        "results = {}\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch = df.iloc[i:i + batch_size]\n",
        "    compounds = batch['compound'].tolist()\n",
        "    sentences = batch['sentence'].tolist()\n",
        "    batch_results = generate_paraphrases_batched_3(compounds, sentences)\n",
        "    results.update(batch_results)\n",
        "\n",
        "# Map results back to DataFrame\n",
        "df['gpt_prompt_3_resp'] = df['compound'].map(results)"
      ],
      "metadata": {
        "id": "Sz1AW8RSfXOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['compound', 'sentence_type', 'sentence', 'gpt_prompt_1_resp', 'gpt_prompt_2_resp', 'gpt_prompt_3_resp']].to_csv('gpt_prompt_responses.csv', index=False)"
      ],
      "metadata": {
        "id": "vDAl6d5WglU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPT Prompt Experiment 4 (new)"
      ],
      "metadata": {
        "id": "xWGGZrLU4UqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT Prompt #4\n",
        "\n",
        "import json\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_PROJECT_KEY'))\n",
        "\n",
        "def generate_paraphrases_batched_2(compound, sentence):\n",
        "    \"\"\"\n",
        "    Generate paraphrases in batches using GPT-4.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are a linguistics expert specializing in idioms. For each of the idioms below, do the following steps aloud (in writing):\n",
        "1. Give a verbose explanation of the idiom, including what connotations it carries or undertones it evokes.\n",
        "2. List three potential definitions, no longer than 20 words each, that capture the essence of the phrase in a general manner.\n",
        "3. Choose the best definition.\n",
        "\n",
        "Example #1:\n",
        "Input:\n",
        "{{\n",
        "  \"compound\": \"cold turkey\",\n",
        "  \"sentence\": \"I've decided to go cold turkey on the cigarettes again\"\n",
        "}}\n",
        "Idiom: \"cold turkey\"\n",
        "Definition: \"Abruptly quitting a habit or addiction, overcoming discomfort or pain, requiring determination.\"\n",
        "\n",
        "Example #2:\n",
        "Idiom: \"piece of cake\"\n",
        "Definition: \"Easy, simple to accomplish, requiring little effort, not a problem.\"\n",
        "\n",
        "Input:\n",
        "{compound}\n",
        "\n",
        "Respond in this format:\n",
        "{{\"idioms\": [\n",
        "    {{\"idiom\": \"cold turkey\", \"verbose_definition\": \"<verbose_definition>\", \"possible_definitions\": \"<three possible definitions>\", \"definition\": \"Abruptly quitting a habit, marked by discomfort and determination.\"}},\n",
        "    {{\"idiom\": \"<another idiom>\", \"verbose_definition\": \"<verbose_definition>\", \"possible_definitions\": \"<three possible definitions>\" , \"definition\": \"<its definition>\" }}\n",
        "]}}\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "        )\n",
        "        content = json.loads(response.choices[0].message.content.strip())\n",
        "        results = {item[\"idiom\"]: item[\"definition\"] for item in content[\"idioms\"]}\n",
        "        for item in content[\"idioms\"]:\n",
        "            print(f\"Idiom: {item['idiom']}\\nVerbose: {item['verbose_definition']}\\nPossible: {item['possible_definitions']}\\nDefinition: {item['definition']}\\n\")\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating paraphrases: {e}\")\n",
        "        return {}"
      ],
      "metadata": {
        "id": "Xj63QQlQ4c8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment and model configurations"
      ],
      "metadata": {
        "id": "-WpYrv_IWIai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiments config"
      ],
      "metadata": {
        "id": "wJ37qEGzTiIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiments = [\n",
        "    {\n",
        "        \"name\": \"Baseline (Sentences)\",\n",
        "        \"text_inputs\": df['sentence']\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"NC-Only\",\n",
        "        \"text_inputs\": df['compound']\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"GPT Prompt 1\",\n",
        "        \"text_inputs\": df['gpt_prompt_1_resp']\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"GPT Prompt 2\",\n",
        "        \"text_inputs\": df['gpt_prompt_2_resp']\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"GPT Prompt 3\",\n",
        "        \"text_inputs\": df['gpt_prompt_3_resp']\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"GPT Prompt 3 with nc for literal\",\n",
        "        \"text_inputs\": df['gpt_prompt_3_with_nc_for_literal']\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"GPT Prompt 3 with sentence for literal\",\n",
        "        \"text_inputs\": df['gpt_prompt_3_with_sentence_for_literal']\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "XHmKFDbtTdqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gpt_prompt_4_results.csv', mode=\"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    prompt_4_results = [row for row in reader]\n",
        "prompt_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QUBAZjiog_AN",
        "outputId": "a7313a2c-16e4-4455-a028-5cee4f70cbcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'phrase': 'elbow grease',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a great deal of physical effort or hard work, especially in the context of a difficult task requiring physical exertion.'},\n",
              " {'phrase': 'night owl',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'A person who stays up and is active late into the night.'},\n",
              " {'phrase': 'heart of gold',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'One who is generous, caring, and sympathetic towards others.'},\n",
              " {'phrase': 'agony aunt',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a person or organization providing advice, information, and forecasts to solve problems or answer queries.'},\n",
              " {'phrase': 'shrinking violet',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'something that is not overlooked or underestimated; in context, the wine has a bold, assertive flavor.'},\n",
              " {'phrase': 'green fingers',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'fingers that are colored green, probably due to a staining substance like paint.'},\n",
              " {'phrase': 'ancient history',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'the history of ancient civilizations, in this case Greece and Rome.'},\n",
              " {'phrase': 'banana republic',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a politically unstable country with a economy dependent on the exportation of limited-resource product, which is presided over by a corrupt, inept, or self-serving elite.'},\n",
              " {'phrase': \"devil's advocate\",\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'someone who presents a counter argument, or argues the opposing perspective.'},\n",
              " {'phrase': 'private eye',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a private detective suggesting obtaining information through dubious means.'},\n",
              " {'phrase': 'pipe dream',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'an unachievable or unrealistic goal, aspiration, or plan.'},\n",
              " {'phrase': 'piece of cake',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a portion of a sweet baked dessert typically containing flour, sugar, and other ingredients.'},\n",
              " {'phrase': 'rocket science',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'something very complex, challenging, or requiring strong intellect or technical knowledge.'},\n",
              " {'phrase': 'brass ring',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a ring made of brass used as a part of the frame for a composite gaming chip.'},\n",
              " {'phrase': 'apples and oranges',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'actual fruit types namely apples and oranges.'},\n",
              " {'phrase': 'nest egg',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a sum of money saved for the future or a specific purpose'},\n",
              " {'phrase': 'ghost town',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a deserted town which is ascribed in this sentence as haunted by restless spirits.'},\n",
              " {'phrase': 'bull market',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a financial market condition where the prices of securities are rising or are expected to rise, often producing widespread optimism.'},\n",
              " {'phrase': 'beached whale',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'representing something large, out of place and unable to adapt or progress.'},\n",
              " {'phrase': 'flower child',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a personified flower characterized by the option to change the appearance of their petals and leaves, in the context of a game, representing a character with botanical features.'},\n",
              " {'phrase': 'copy cat',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'someone who copies, imitates or mimics the behavior, actions, or techniques of someone else.'},\n",
              " {'phrase': 'lounge lizard',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a man who frequents bars, nightclubs, or other social venues, often dressed stylishly or slickly, and having a seductive but sometimes sleazy demeanor.'},\n",
              " {'phrase': 'secret santa',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'someone who does good deeds or gives gifts in secret.'},\n",
              " {'phrase': 'dirty word',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a word that is physically made dirty by mud.'},\n",
              " {'phrase': 'close shave',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a shave so close that the skin is very smooth but can possibly lead to skin irritation or ingrown hairs.'},\n",
              " {'phrase': 'donkey work',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'tasks or work related to the care of a donkey, especially in a stable.'},\n",
              " {'phrase': 'bear market',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a condition in a financial market where prices are falling or are expected to fall.'},\n",
              " {'phrase': 'top dog',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a person, group, or thing in a position of authority, dominance or superiority in a particular area.'},\n",
              " {'phrase': \"dog's dinner\",\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'food prepared for a dog.'},\n",
              " {'phrase': 'white hat',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'ethical computer hacking, or ethical SEO practices etc., aligned to the requirements and standards set by the respective governing body.'},\n",
              " {'phrase': 'smoking gun',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'incontrovertible evidence or proof.'},\n",
              " {'phrase': 'old flame',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a person with whom one had a romantic relationship in the past.'},\n",
              " {'phrase': 'zebra crossing',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a zebra, the animal, moving from one side of the road to the other, likely causing a brief traffic delay.'},\n",
              " {'phrase': 'eye candy',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'candy or sweets that are visually appealing or aesthetically pleasing to look at.'},\n",
              " {'phrase': 'ivory tower',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a state of privileged seclusion or separation from the facts and practicalities of the real world.'},\n",
              " {'phrase': 'black sheep',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'something or someone who is considered less valuable, significant or respectable compared to others in a group.'},\n",
              " {'phrase': 'armchair critic',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a critic who reviews furniture while using or sitting in it.'},\n",
              " {'phrase': 'gravy train',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'joining a situation or activity that allows one to make a lot of money with very little effort or work.'},\n",
              " {'phrase': 'rat race',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'the exhausting, competitive pursuit of wealth or success in a busy, high-stress environment, often resulting in a lack of time for leisure or family.'},\n",
              " {'phrase': 'hot potato',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a potato that has been heated and is ready to be eaten.'},\n",
              " {'phrase': 'spring chicken',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a person who is young and inexperienced.'},\n",
              " {'phrase': 'love triangle',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a pendant in the shape of a triangle, decorated with heart patterns.'},\n",
              " {'phrase': 'black box',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a box or object that is black in color and provides specific technical benefits, such as EMI/RFI shielding and secure mounting'},\n",
              " {'phrase': 'hen party',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a gathering of hens, likely for eating and socializing.'},\n",
              " {'phrase': 'acid test',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a chemical test using acid, specifically to check for the presence of gold.'},\n",
              " {'phrase': 'inner circle',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a small, close-knit, and influential group within a larger one.'},\n",
              " {'phrase': 'bad apple',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a person (or people) who negatively impacts an environment through poor behavior or negative attitudes.'},\n",
              " {'phrase': 'honey trap',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a deceptive act or strategy used to entrap or manipulate someone, in this case through tricks or lures on the internet utilized by cybercriminals.'},\n",
              " {'phrase': 'pins and needles',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'thin, pointed pieces of metal with a head, used especially for fastening fabric, and thin metal rods with a sharp point at one end and a small decorative piece at the other, used especially in sewing.'},\n",
              " {'phrase': 'bun in the oven',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'heating a stale bun in the oven to restore its freshness and extend its usability, especially for making meals like lunch.'},\n",
              " {'phrase': 'loan shark',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'an entity that lends money at exorbitantly high interest rates, often backed by blackmail or threats of violence.'},\n",
              " {'phrase': 'open book',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a person who is open and candid, making their thoughts, feelings, or motives readily discernible to others.'},\n",
              " {'phrase': 'baby blues',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'postpartum depression that characteristically afflicts mothers within a few days after childbirth, usually subsiding within a week or two.'},\n",
              " {'phrase': 'silver bullet',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a bullet made from silver, typically associated with killing supernatural creatures like werewolves in folklore.'},\n",
              " {'phrase': 'brain surgery',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'something highly difficult, complex or requiring exceptional intelligence.'},\n",
              " {'phrase': 'red flag',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a warning signal or an alarming sign of a particular problem that requires attention.'},\n",
              " {'phrase': 'white elephant',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a burdensome, expensive or extravagant possession or venture, the maintenance of which is out of proportion to its usefulness or value.'},\n",
              " {'phrase': 'two-way street',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a street allowing traffic to travel in two directions.'},\n",
              " {'phrase': 'rat run',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'A minor, typically residential street used by drivers during peak periods to avoid congestion on main roads.'},\n",
              " {'phrase': 'graveyard shift',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a late-night or overnight shift of work or duty.'},\n",
              " {'phrase': 'dirty money',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'money that is earned through illegal activities and is difficult to track by the authorities.'},\n",
              " {'phrase': 'high life',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'an extravagant or luxurious lifestyle characterized by wealth and indulgences.'},\n",
              " {'phrase': 'pain in the neck',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'discomfort or actual physical pain located in the neck area.'},\n",
              " {'phrase': 'guinea pig',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a subject in an experiment or trial; a person used to test an idea, method, or product.'},\n",
              " {'phrase': \"cat's eyes\",\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'reflectors mounted in road surfaces as a safety measure to aid in line visibility at night or poor weather conditions'},\n",
              " {'phrase': 'cold turkey',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'the meat of a turkey which has been cooked and then cooled for serving.'},\n",
              " {'phrase': 'low-hanging fruit',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'Tasks, problems, or targets that are comparatively easy to achieve or solve.'},\n",
              " {'phrase': 'busy bee',\n",
              "  'usage': 'idiomatic',\n",
              "  'meaning': 'a person who is always active, engaged, and industrious.'},\n",
              " {'phrase': 'wet blanket',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a blanket that is literally wet, and used to prevent a fire from spreading.'},\n",
              " {'phrase': 'chicken feed',\n",
              "  'usage': 'literal',\n",
              "  'meaning': 'a type of feed intended for feeding chickens.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['gpt_prompt_4_resp'] = [res['meaning'] for res in prompt_4_results]\n",
        "df['gpt_prompt_4_type'] = [res['usage'] for res in prompt_4_results]\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LF_gbBxqg8Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = []\n",
        "for i in range(len(df)):\n",
        "  if (df.iloc[i]['gpt_prompt_4_type'] == 'idiomatic'):\n",
        "     text_input.append(df.iloc[i]['gpt_prompt_4_resp'])\n",
        "  else:\n",
        "    text_input.append(df.iloc[i]['sentence'])\n",
        "df['text_input_exp_4'] = text_input\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "cAV8tsBuXHUX",
        "outputId": "12f4dc43-5155-41b6-e908-ebd52dfc6994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             compound  subset sentence_type  \\\n",
              "0        elbow grease   Train     idiomatic   \n",
              "1           night owl   Train     idiomatic   \n",
              "2       heart of gold   Train     idiomatic   \n",
              "3          agony aunt  Sample     idiomatic   \n",
              "4    shrinking violet   Train     idiomatic   \n",
              "..                ...     ...           ...   \n",
              "65        cold turkey  Sample       literal   \n",
              "66  low-hanging fruit   Train     idiomatic   \n",
              "67           busy bee   Train     idiomatic   \n",
              "68        wet blanket   Train       literal   \n",
              "69       chicken feed   Train       literal   \n",
              "\n",
              "                                             sentence  \\\n",
              "0   It took a lot of elbow grease to get the old e...   \n",
              "1   It's a constant battle for us, as he is a morn...   \n",
              "2   Even the somewhat seedy failed private eye has...   \n",
              "3   ESA's Space Weather Office is like Europe's st...   \n",
              "4   This aged, rich wine is no shrinking violet wi...   \n",
              "..                                                ...   \n",
              "65  When you're serving cold turkey, take out only...   \n",
              "66  Howard said there was a lot of low-hanging fru...   \n",
              "67  There's no need to worry if you're a busy bee ...   \n",
              "68  Wet blankets draped over neighboring cabins pr...   \n",
              "69  Feed pets inside and do not leave pet, livesto...   \n",
              "\n",
              "                                       expected_order      image1_name  \\\n",
              "0   ['35234427395.png', '53378381715.png', '399382...  35234427395.png   \n",
              "1   ['61697797701.png', '93189810779.png', '893752...  00982495584.png   \n",
              "2   ['86137977215.png', '78062290185.png', '542405...  54240592941.png   \n",
              "3   ['83600499282.png', '57658144685.png', '025128...  02512838127.png   \n",
              "4   ['77861539717.png', '68016869942.png', '118443...  11844321898.png   \n",
              "..                                                ...              ...   \n",
              "65  ['47545447824.png', '78631376435.png', '162393...  16239351344.png   \n",
              "66  ['87359560017.png', '28404294077.png', '911178...  20825217491.png   \n",
              "67  ['33246843335.png', '27532602036.png', '505168...  13914680332.png   \n",
              "68  ['28147683669.png', '88635314726.png', '393854...  03496279195.png   \n",
              "69  ['37795851361.png', '57390097066.png', '212710...  21271058237.png   \n",
              "\n",
              "                                       image1_caption      image2_name  \\\n",
              "0   The image depicts a hand holding a sponge and ...  39938261459.png   \n",
              "1   The image depicts a nighttime scene with a lar...  61697797701.png   \n",
              "2   The image depicts a large, metallic safe with ...  78062290185.png   \n",
              "3   The image depicts a serene outdoor scene featu...  32964421720.png   \n",
              "4   The image depicts a bouquet of purple tulips a...  45394842176.png   \n",
              "..                                                ...              ...   \n",
              "65  The image depicts a woven basket filled with a...  47545447824.png   \n",
              "66  The image depicts a plate of chocolate chip co...  28404294077.png   \n",
              "67  The image depicts a cartoon-style bee flying o...  27532602036.png   \n",
              "68  The image depicts a group of seven people stan...  28147683669.png   \n",
              "69  The image depicts a hand holding a stack of ba...  37795851361.png   \n",
              "\n",
              "                                       image2_caption      image3_name  ...  \\\n",
              "0   The image depicts a hand wearing a yellow work...  53378381715.png  ...   \n",
              "1   The image depicts a cartoon-style illustration...  89375227504.png  ...   \n",
              "2   The image depicts a joyful scene featuring a y...  86137977215.png  ...   \n",
              "3   The image depicts a cartoon-style illustration...  57658144685.png  ...   \n",
              "4   The image depicts a magnifying glass, commonly...  68016869942.png  ...   \n",
              "..                                                ...              ...  ...   \n",
              "65  The image depicts a whimsical, cartoon-style b...  53986444390.png  ...   \n",
              "66  The image depicts a scene from a motorsport ev...  42866872474.png  ...   \n",
              "67  The image depicts a woman walking in an office...  33246843335.png  ...   \n",
              "68  The image depicts a rolled-up blanket with fur...  39385479814.png  ...   \n",
              "69  The image depicts two cartoon-style chickens s...  48528496115.png  ...   \n",
              "\n",
              "        image4_name                                     image4_caption  \\\n",
              "0   54879908369.png  The image depicts a person wearing knee pads a...   \n",
              "1   93189810779.png  The image depicts a cartoon-style illustration...   \n",
              "2   90660547751.png  The image depicts a futuristic, stylized space...   \n",
              "3   83600499282.png  The image depicts a person sitting at a desk, ...   \n",
              "4   77861539717.png  The image depicts an animated character with c...   \n",
              "..              ...                                                ...   \n",
              "65  65148693634.png  The image depicts an autumn scene in a forest....   \n",
              "66  87359560017.png  The image depicts a stylized target with three...   \n",
              "67  50206720330.png  The image depicts a woodpecker perched on a tr...   \n",
              "68  64522104806.png  The image depicts a cartoon-style police offic...   \n",
              "69  57390097066.png  The image depicts a cartoon rooster standing o...   \n",
              "\n",
              "        image5_name                                     image5_caption  \\\n",
              "0   74852536462.png  The image depicts a person wearing a black out...   \n",
              "1   93541983868.png  The image depicts a dumbbell, which is a commo...   \n",
              "2   92088849364.png  The image depicts a stylized, artistic represe...   \n",
              "3   92533456778.png  The image depicts a cartoon character of a wom...   \n",
              "4   97482048489.png  The image is a colorful and vibrant illustrati...   \n",
              "..              ...                                                ...   \n",
              "65  78631376435.png  The image depicts a whimsical, cartoon-style s...   \n",
              "66  91117857131.png  The image depicts an orange tree with a dense ...   \n",
              "67  50516840411.png  The image depicts a bee perched on a small roc...   \n",
              "68  88635314726.png  The image depicts a cozy, rolled-up blanket wi...   \n",
              "69  95410072019.png  The image shows a hand holding two coins. The ...   \n",
              "\n",
              "                                          image_paths  \\\n",
              "0   [train/elbow grease/35234427395.png, train/elb...   \n",
              "1   [train/night owl/00982495584.png, train/night ...   \n",
              "2   [train/heart of gold/54240592941.png, train/he...   \n",
              "3   [train/agony aunt/02512838127.png, train/agony...   \n",
              "4   [train/shrinking violet/11844321898.png, train...   \n",
              "..                                                ...   \n",
              "65  [train/cold turkey/16239351344.png, train/cold...   \n",
              "66  [train/low-hanging fruit/20825217491.png, trai...   \n",
              "67  [train/busy bee/13914680332.png, train/busy be...   \n",
              "68  [train/wet blanket/03496279195.png, train/wet ...   \n",
              "69  [train/chicken feed/21271058237.png, train/chi...   \n",
              "\n",
              "                                        image_idx_map expected_order_indices  \\\n",
              "0   {'35234427395.png': 0, '39938261459.png': 1, '...        [0, 2, 1, 4, 3]   \n",
              "1   {'00982495584.png': 0, '61697797701.png': 1, '...        [1, 3, 2, 0, 4]   \n",
              "2   {'54240592941.png': 0, '78062290185.png': 1, '...        [2, 1, 0, 4, 3]   \n",
              "3   {'02512838127.png': 0, '32964421720.png': 1, '...        [3, 2, 0, 1, 4]   \n",
              "4   {'11844321898.png': 0, '45394842176.png': 1, '...        [3, 2, 0, 1, 4]   \n",
              "..                                                ...                    ...   \n",
              "65  {'16239351344.png': 0, '47545447824.png': 1, '...        [1, 4, 0, 2, 3]   \n",
              "66  {'20825217491.png': 0, '28404294077.png': 1, '...        [3, 1, 4, 2, 0]   \n",
              "67  {'13914680332.png': 0, '27532602036.png': 1, '...        [2, 1, 4, 0, 3]   \n",
              "68  {'03496279195.png': 0, '28147683669.png': 1, '...        [1, 4, 2, 0, 3]   \n",
              "69  {'21271058237.png': 0, '37795851361.png': 1, '...        [1, 3, 0, 4, 2]   \n",
              "\n",
              "                                    gpt_prompt_4_resp gpt_prompt_4_type  \\\n",
              "0   a great deal of physical effort or hard work, ...         idiomatic   \n",
              "1   A person who stays up and is active late into ...         idiomatic   \n",
              "2   One who is generous, caring, and sympathetic t...         idiomatic   \n",
              "3   a person or organization providing advice, inf...         idiomatic   \n",
              "4   something that is not overlooked or underestim...         idiomatic   \n",
              "..                                                ...               ...   \n",
              "65  the meat of a turkey which has been cooked and...           literal   \n",
              "66  Tasks, problems, or targets that are comparati...         idiomatic   \n",
              "67  a person who is always active, engaged, and in...         idiomatic   \n",
              "68  a blanket that is literally wet, and used to p...           literal   \n",
              "69      a type of feed intended for feeding chickens.           literal   \n",
              "\n",
              "                                     text_input_exp_4  \n",
              "0   a great deal of physical effort or hard work, ...  \n",
              "1   A person who stays up and is active late into ...  \n",
              "2   One who is generous, caring, and sympathetic t...  \n",
              "3   a person or organization providing advice, inf...  \n",
              "4   something that is not overlooked or underestim...  \n",
              "..                                                ...  \n",
              "65  When you're serving cold turkey, take out only...  \n",
              "66  Tasks, problems, or targets that are comparati...  \n",
              "67  a person who is always active, engaged, and in...  \n",
              "68  Wet blankets draped over neighboring cabins pr...  \n",
              "69  Feed pets inside and do not leave pet, livesto...  \n",
              "\n",
              "[70 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ebc9f3c-9d05-4aa3-be24-c7de7f19fe46\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>compound</th>\n",
              "      <th>subset</th>\n",
              "      <th>sentence_type</th>\n",
              "      <th>sentence</th>\n",
              "      <th>expected_order</th>\n",
              "      <th>image1_name</th>\n",
              "      <th>image1_caption</th>\n",
              "      <th>image2_name</th>\n",
              "      <th>image2_caption</th>\n",
              "      <th>image3_name</th>\n",
              "      <th>...</th>\n",
              "      <th>image4_name</th>\n",
              "      <th>image4_caption</th>\n",
              "      <th>image5_name</th>\n",
              "      <th>image5_caption</th>\n",
              "      <th>image_paths</th>\n",
              "      <th>image_idx_map</th>\n",
              "      <th>expected_order_indices</th>\n",
              "      <th>gpt_prompt_4_resp</th>\n",
              "      <th>gpt_prompt_4_type</th>\n",
              "      <th>text_input_exp_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>elbow grease</td>\n",
              "      <td>Train</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>It took a lot of elbow grease to get the old e...</td>\n",
              "      <td>['35234427395.png', '53378381715.png', '399382...</td>\n",
              "      <td>35234427395.png</td>\n",
              "      <td>The image depicts a hand holding a sponge and ...</td>\n",
              "      <td>39938261459.png</td>\n",
              "      <td>The image depicts a hand wearing a yellow work...</td>\n",
              "      <td>53378381715.png</td>\n",
              "      <td>...</td>\n",
              "      <td>54879908369.png</td>\n",
              "      <td>The image depicts a person wearing knee pads a...</td>\n",
              "      <td>74852536462.png</td>\n",
              "      <td>The image depicts a person wearing a black out...</td>\n",
              "      <td>[train/elbow grease/35234427395.png, train/elb...</td>\n",
              "      <td>{'35234427395.png': 0, '39938261459.png': 1, '...</td>\n",
              "      <td>[0, 2, 1, 4, 3]</td>\n",
              "      <td>a great deal of physical effort or hard work, ...</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>a great deal of physical effort or hard work, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>night owl</td>\n",
              "      <td>Train</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>It's a constant battle for us, as he is a morn...</td>\n",
              "      <td>['61697797701.png', '93189810779.png', '893752...</td>\n",
              "      <td>00982495584.png</td>\n",
              "      <td>The image depicts a nighttime scene with a lar...</td>\n",
              "      <td>61697797701.png</td>\n",
              "      <td>The image depicts a cartoon-style illustration...</td>\n",
              "      <td>89375227504.png</td>\n",
              "      <td>...</td>\n",
              "      <td>93189810779.png</td>\n",
              "      <td>The image depicts a cartoon-style illustration...</td>\n",
              "      <td>93541983868.png</td>\n",
              "      <td>The image depicts a dumbbell, which is a commo...</td>\n",
              "      <td>[train/night owl/00982495584.png, train/night ...</td>\n",
              "      <td>{'00982495584.png': 0, '61697797701.png': 1, '...</td>\n",
              "      <td>[1, 3, 2, 0, 4]</td>\n",
              "      <td>A person who stays up and is active late into ...</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>A person who stays up and is active late into ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>heart of gold</td>\n",
              "      <td>Train</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>Even the somewhat seedy failed private eye has...</td>\n",
              "      <td>['86137977215.png', '78062290185.png', '542405...</td>\n",
              "      <td>54240592941.png</td>\n",
              "      <td>The image depicts a large, metallic safe with ...</td>\n",
              "      <td>78062290185.png</td>\n",
              "      <td>The image depicts a joyful scene featuring a y...</td>\n",
              "      <td>86137977215.png</td>\n",
              "      <td>...</td>\n",
              "      <td>90660547751.png</td>\n",
              "      <td>The image depicts a futuristic, stylized space...</td>\n",
              "      <td>92088849364.png</td>\n",
              "      <td>The image depicts a stylized, artistic represe...</td>\n",
              "      <td>[train/heart of gold/54240592941.png, train/he...</td>\n",
              "      <td>{'54240592941.png': 0, '78062290185.png': 1, '...</td>\n",
              "      <td>[2, 1, 0, 4, 3]</td>\n",
              "      <td>One who is generous, caring, and sympathetic t...</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>One who is generous, caring, and sympathetic t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>agony aunt</td>\n",
              "      <td>Sample</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>ESA's Space Weather Office is like Europe's st...</td>\n",
              "      <td>['83600499282.png', '57658144685.png', '025128...</td>\n",
              "      <td>02512838127.png</td>\n",
              "      <td>The image depicts a serene outdoor scene featu...</td>\n",
              "      <td>32964421720.png</td>\n",
              "      <td>The image depicts a cartoon-style illustration...</td>\n",
              "      <td>57658144685.png</td>\n",
              "      <td>...</td>\n",
              "      <td>83600499282.png</td>\n",
              "      <td>The image depicts a person sitting at a desk, ...</td>\n",
              "      <td>92533456778.png</td>\n",
              "      <td>The image depicts a cartoon character of a wom...</td>\n",
              "      <td>[train/agony aunt/02512838127.png, train/agony...</td>\n",
              "      <td>{'02512838127.png': 0, '32964421720.png': 1, '...</td>\n",
              "      <td>[3, 2, 0, 1, 4]</td>\n",
              "      <td>a person or organization providing advice, inf...</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>a person or organization providing advice, inf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shrinking violet</td>\n",
              "      <td>Train</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>This aged, rich wine is no shrinking violet wi...</td>\n",
              "      <td>['77861539717.png', '68016869942.png', '118443...</td>\n",
              "      <td>11844321898.png</td>\n",
              "      <td>The image depicts a bouquet of purple tulips a...</td>\n",
              "      <td>45394842176.png</td>\n",
              "      <td>The image depicts a magnifying glass, commonly...</td>\n",
              "      <td>68016869942.png</td>\n",
              "      <td>...</td>\n",
              "      <td>77861539717.png</td>\n",
              "      <td>The image depicts an animated character with c...</td>\n",
              "      <td>97482048489.png</td>\n",
              "      <td>The image is a colorful and vibrant illustrati...</td>\n",
              "      <td>[train/shrinking violet/11844321898.png, train...</td>\n",
              "      <td>{'11844321898.png': 0, '45394842176.png': 1, '...</td>\n",
              "      <td>[3, 2, 0, 1, 4]</td>\n",
              "      <td>something that is not overlooked or underestim...</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>something that is not overlooked or underestim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>cold turkey</td>\n",
              "      <td>Sample</td>\n",
              "      <td>literal</td>\n",
              "      <td>When you're serving cold turkey, take out only...</td>\n",
              "      <td>['47545447824.png', '78631376435.png', '162393...</td>\n",
              "      <td>16239351344.png</td>\n",
              "      <td>The image depicts a woven basket filled with a...</td>\n",
              "      <td>47545447824.png</td>\n",
              "      <td>The image depicts a whimsical, cartoon-style b...</td>\n",
              "      <td>53986444390.png</td>\n",
              "      <td>...</td>\n",
              "      <td>65148693634.png</td>\n",
              "      <td>The image depicts an autumn scene in a forest....</td>\n",
              "      <td>78631376435.png</td>\n",
              "      <td>The image depicts a whimsical, cartoon-style s...</td>\n",
              "      <td>[train/cold turkey/16239351344.png, train/cold...</td>\n",
              "      <td>{'16239351344.png': 0, '47545447824.png': 1, '...</td>\n",
              "      <td>[1, 4, 0, 2, 3]</td>\n",
              "      <td>the meat of a turkey which has been cooked and...</td>\n",
              "      <td>literal</td>\n",
              "      <td>When you're serving cold turkey, take out only...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>low-hanging fruit</td>\n",
              "      <td>Train</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>Howard said there was a lot of low-hanging fru...</td>\n",
              "      <td>['87359560017.png', '28404294077.png', '911178...</td>\n",
              "      <td>20825217491.png</td>\n",
              "      <td>The image depicts a plate of chocolate chip co...</td>\n",
              "      <td>28404294077.png</td>\n",
              "      <td>The image depicts a scene from a motorsport ev...</td>\n",
              "      <td>42866872474.png</td>\n",
              "      <td>...</td>\n",
              "      <td>87359560017.png</td>\n",
              "      <td>The image depicts a stylized target with three...</td>\n",
              "      <td>91117857131.png</td>\n",
              "      <td>The image depicts an orange tree with a dense ...</td>\n",
              "      <td>[train/low-hanging fruit/20825217491.png, trai...</td>\n",
              "      <td>{'20825217491.png': 0, '28404294077.png': 1, '...</td>\n",
              "      <td>[3, 1, 4, 2, 0]</td>\n",
              "      <td>Tasks, problems, or targets that are comparati...</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>Tasks, problems, or targets that are comparati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>busy bee</td>\n",
              "      <td>Train</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>There's no need to worry if you're a busy bee ...</td>\n",
              "      <td>['33246843335.png', '27532602036.png', '505168...</td>\n",
              "      <td>13914680332.png</td>\n",
              "      <td>The image depicts a cartoon-style bee flying o...</td>\n",
              "      <td>27532602036.png</td>\n",
              "      <td>The image depicts a woman walking in an office...</td>\n",
              "      <td>33246843335.png</td>\n",
              "      <td>...</td>\n",
              "      <td>50206720330.png</td>\n",
              "      <td>The image depicts a woodpecker perched on a tr...</td>\n",
              "      <td>50516840411.png</td>\n",
              "      <td>The image depicts a bee perched on a small roc...</td>\n",
              "      <td>[train/busy bee/13914680332.png, train/busy be...</td>\n",
              "      <td>{'13914680332.png': 0, '27532602036.png': 1, '...</td>\n",
              "      <td>[2, 1, 4, 0, 3]</td>\n",
              "      <td>a person who is always active, engaged, and in...</td>\n",
              "      <td>idiomatic</td>\n",
              "      <td>a person who is always active, engaged, and in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>wet blanket</td>\n",
              "      <td>Train</td>\n",
              "      <td>literal</td>\n",
              "      <td>Wet blankets draped over neighboring cabins pr...</td>\n",
              "      <td>['28147683669.png', '88635314726.png', '393854...</td>\n",
              "      <td>03496279195.png</td>\n",
              "      <td>The image depicts a group of seven people stan...</td>\n",
              "      <td>28147683669.png</td>\n",
              "      <td>The image depicts a rolled-up blanket with fur...</td>\n",
              "      <td>39385479814.png</td>\n",
              "      <td>...</td>\n",
              "      <td>64522104806.png</td>\n",
              "      <td>The image depicts a cartoon-style police offic...</td>\n",
              "      <td>88635314726.png</td>\n",
              "      <td>The image depicts a cozy, rolled-up blanket wi...</td>\n",
              "      <td>[train/wet blanket/03496279195.png, train/wet ...</td>\n",
              "      <td>{'03496279195.png': 0, '28147683669.png': 1, '...</td>\n",
              "      <td>[1, 4, 2, 0, 3]</td>\n",
              "      <td>a blanket that is literally wet, and used to p...</td>\n",
              "      <td>literal</td>\n",
              "      <td>Wet blankets draped over neighboring cabins pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>chicken feed</td>\n",
              "      <td>Train</td>\n",
              "      <td>literal</td>\n",
              "      <td>Feed pets inside and do not leave pet, livesto...</td>\n",
              "      <td>['37795851361.png', '57390097066.png', '212710...</td>\n",
              "      <td>21271058237.png</td>\n",
              "      <td>The image depicts a hand holding a stack of ba...</td>\n",
              "      <td>37795851361.png</td>\n",
              "      <td>The image depicts two cartoon-style chickens s...</td>\n",
              "      <td>48528496115.png</td>\n",
              "      <td>...</td>\n",
              "      <td>57390097066.png</td>\n",
              "      <td>The image depicts a cartoon rooster standing o...</td>\n",
              "      <td>95410072019.png</td>\n",
              "      <td>The image shows a hand holding two coins. The ...</td>\n",
              "      <td>[train/chicken feed/21271058237.png, train/chi...</td>\n",
              "      <td>{'21271058237.png': 0, '37795851361.png': 1, '...</td>\n",
              "      <td>[1, 3, 0, 4, 2]</td>\n",
              "      <td>a type of feed intended for feeding chickens.</td>\n",
              "      <td>literal</td>\n",
              "      <td>Feed pets inside and do not leave pet, livesto...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ebc9f3c-9d05-4aa3-be24-c7de7f19fe46')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ebc9f3c-9d05-4aa3-be24-c7de7f19fe46 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ebc9f3c-9d05-4aa3-be24-c7de7f19fe46');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4c2a84d3-d2fe-407b-9e30-bc0887d55819\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c2a84d3-d2fe-407b-9e30-bc0887d55819')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4c2a84d3-d2fe-407b-9e30-bc0887d55819 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ec72d569-f21e-4340-8b1e-f754db074106\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ec72d569-f21e-4340-8b1e-f754db074106 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "experiments = [{\n",
        "        \"name\": \"GPT Prompt 4 with sentence if predicted literal\",\n",
        "        \"text_inputs\": df['text_input_exp_4']\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "THWzmHH3Qp8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Models config"
      ],
      "metadata": {
        "id": "ZtIai-zDl1tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlignProcessor, AlignModel\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "models = [\n",
        "    {\n",
        "        \"base_model\": \"CLIP\",\n",
        "        \"model_name\": \"ViT-B/32\",\n",
        "        \"model\": clip.load(\"ViT-B/32\", device)[0],\n",
        "        \"preprocess\": clip.load(\"ViT-B/32\", device)[1]\n",
        "    },\n",
        "    # {\n",
        "    #     \"base_model\": \"CLIP\",\n",
        "    #     \"model_name\": \"ViT-L/14\",\n",
        "    #     \"model\": clip.load(\"ViT-L/14\", device)[0],\n",
        "    #     \"preprocess\": clip.load(\"ViT-L/14\", device)[1]\n",
        "    # },\n",
        "    # {\n",
        "    #     \"base_model\": \"CLIP\",\n",
        "    #     \"model_name\": \"RN50x64\",\n",
        "    #     \"model\": clip.load(\"RN50x64\", device)[0],\n",
        "    #     \"preprocess\": clip.load(\"RN50x64\", device)[1]\n",
        "    # },\n",
        "    # {\n",
        "    #     \"base_model\": \"Align\",\n",
        "    #     \"model_name\": \"Base\",\n",
        "    #     \"model\": AlignModel.from_pretrained(\"kakaobrain/align-base\"),\n",
        "    #     \"preprocess\": AlignProcessor.from_pretrained(\"kakaobrain/align-base\")\n",
        "    # }\n",
        "]"
      ],
      "metadata": {
        "id": "pd77vRZCFHOD",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "613594b6-ec90-4f55-8421-089cb72ebc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:03<00:00, 96.0MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openclip_model_version = \"ViT-B-32\"\n",
        "model_openclip, _, preprocess_openclip = open_clip.create_model_and_transforms(openclip_model_version, pretrained='laion2b_s34b_b79k')\n",
        "model_openclip.to(device)\n",
        "model_openclip.eval()  # model in train mode by default, impacts some models with BatchNorm or stochastic depth active\n",
        "\n",
        "models.append({\n",
        "    \"base_model\": \"open_clip\",\n",
        "    \"model_name\": openclip_model_version,\n",
        "    \"model\": model_openclip,\n",
        "    \"preprocess\": preprocess_openclip\n",
        "})"
      ],
      "metadata": {
        "id": "D3Ik9-e_OQlO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "46e263745bfe42cba1641ccd22a583df",
            "009c03518f504c37929deeb8fdc1f45f",
            "6f63427ed5524f2b853db233a9930ba1",
            "c9996590005b4a6e8452ab677d8b8bdd",
            "e8d60c1dc5984c828b91609211e2542e",
            "789460fd175a46dfbaeec46cada512b7",
            "a16b29c632334c38afaa2f0c5300d17a",
            "8f90ee054b17415795c3c85d1984c96d",
            "2fc90f4f752141dfb14c4d4e02c85c1a",
            "322054a5c1c547d197c1213ebed9ffea",
            "56537b9780ab48489916fc4ad79ff42f"
          ]
        },
        "outputId": "e6fbc768-dc53-47f0-d319-c934a56743dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "open_clip_pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46e263745bfe42cba1641ccd22a583df"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RUN ALL"
      ],
      "metadata": {
        "id": "Ft0xM40xTWTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_inputs = []\n",
        "for i in range(len(df)):\n",
        "  row = df.iloc[i]\n",
        "  text_inputs.append([row['gpt_prompt_4_resp'], row['gpt_prompt_4_type'], row['sentence'], row['compound']])"
      ],
      "metadata": {
        "id": "DMG1hsecc7xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for exp in experiments:\n",
        "  print(f\"\\nRunning \\\"{exp['name']}\\\" on {len(models)} models...\")\n",
        "  for idx, conf in enumerate(models):\n",
        "    print(f\"\\nModel [{idx+1}/{len(models)}]: {conf['model_name']} ({conf['base_model']})\")\n",
        "    metrics, preds, confidence = run_experiment_multiple_text_inputs(\n",
        "        model=conf['model'],\n",
        "        processor=conf['preprocess'],\n",
        "        df=df,\n",
        "        image_paths=df['image_paths'],\n",
        "        text_inputs=text_inputs,\n",
        "        model_name=conf['model_name'],\n",
        "        experiment_name=exp['name'],\n",
        "        base_model=conf['base_model']\n",
        "    )\n",
        "    save_predictions(\n",
        "        df=df,\n",
        "        image_paths=df['image_paths'],\n",
        "        predictions=preds,\n",
        "        confidence_scores=confidence,\n",
        "        metrics=metrics,\n",
        "        prefix=f\"{conf['base_model']}_{conf['model_name']}_{exp['name'].lower()}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "19fyQzy0cAaT",
        "outputId": "22c5673e-614a-428a-f6d9-d393cc97eaa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running \"GPT Prompt 4 with sentence if predicted literal\" on 1 models...\n",
            "\n",
            "Model [1/1]: ViT-B/32 (CLIP)\n",
            "Results saved to experiment_results.csv\n",
            "Top-1 Accuracy: 55.71%\n",
            "Average Spearman Correlation: 0.20\n",
            "Average Weighted Accuracy: 0.41\n",
            "Predictions saved to predictions/CLIP_ViT-B32_gpt_prompt_4_with_sentence_if_predicted_literal_preds.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run all experiments on all models\n",
        "for exp in experiments:\n",
        "    print(f\"\\nRunning \\\"{exp['name']}\\\" on {len(models)} models...\")\n",
        "\n",
        "    for idx, conf in enumerate(models):\n",
        "      print(f\"\\nModel [{idx+1}/{len(models)}]: {conf['model_name']} ({conf['base_model']})\")\n",
        "\n",
        "      metrics, preds, confidence = run_experiment(\n",
        "          model=conf['model'],\n",
        "          processor=conf['preprocess'],\n",
        "          df=df,\n",
        "          image_paths=df['image_paths'],\n",
        "          text_inputs=exp['text_inputs'],\n",
        "          model_name=conf['model_name'],\n",
        "          experiment_name=exp['name'],\n",
        "          base_model=conf['base_model']\n",
        "      )\n",
        "      save_predictions(\n",
        "          df=df,\n",
        "          image_paths=df['image_paths'],\n",
        "          predictions=preds,\n",
        "          confidence_scores=confidence,\n",
        "          metrics=metrics,\n",
        "          prefix=f\"{conf['base_model']}_{conf['model_name']}_{exp['name'].lower()}\"\n",
        "      )"
      ],
      "metadata": {
        "id": "0TLSC5-EUJw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5585fa35-e838-4214-f3a7-69acf34d548b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running \"GPT Prompt 4 with sentence if predicted literal\" on 5 models...\n",
            "\n",
            "Model [1/5]: ViT-B/32 (CLIP)\n",
            "Results saved to experiment_results.csv\n",
            "Top-1 Accuracy: 57.14%\n",
            "Average Spearman Correlation: 0.20\n",
            "Average Weighted Accuracy: 0.43\n",
            "Predictions saved to predictions/CLIP_ViT-B32_gpt_prompt_4_with_sentence_if_predicted_literal_preds.csv\n",
            "\n",
            "Model [2/5]: ViT-L/14 (CLIP)\n",
            "Results saved to experiment_results.csv\n",
            "Top-1 Accuracy: 65.71%\n",
            "Average Spearman Correlation: 0.24\n",
            "Average Weighted Accuracy: 0.49\n",
            "Predictions saved to predictions/CLIP_ViT-L14_gpt_prompt_4_with_sentence_if_predicted_literal_preds.csv\n",
            "\n",
            "Model [3/5]: RN50x64 (CLIP)\n",
            "Results saved to experiment_results.csv\n",
            "Top-1 Accuracy: 61.43%\n",
            "Average Spearman Correlation: 0.27\n",
            "Average Weighted Accuracy: 0.43\n",
            "Predictions saved to predictions/CLIP_RN50x64_gpt_prompt_4_with_sentence_if_predicted_literal_preds.csv\n",
            "\n",
            "Model [4/5]: Base (Align)\n",
            "Results saved to experiment_results.csv\n",
            "Top-1 Accuracy: 67.14%\n",
            "Average Spearman Correlation: 0.20\n",
            "Average Weighted Accuracy: 0.49\n",
            "Predictions saved to predictions/Align_Base_gpt_prompt_4_with_sentence_if_predicted_literal_preds.csv\n",
            "\n",
            "Model [5/5]: ViT-B-32 (open_clip)\n",
            "Results saved to experiment_results.csv\n",
            "Top-1 Accuracy: 62.86%\n",
            "Average Spearman Correlation: 0.23\n",
            "Average Weighted Accuracy: 0.44\n",
            "Predictions saved to predictions/open_clip_ViT-B-32_gpt_prompt_4_with_sentence_if_predicted_literal_preds.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "df[['compound', 'sentence_type', 'sentence', 'gpt_prompt_1_resp', 'gpt_prompt_2_resp', 'gpt_prompt_3_resp', 'gpt_prompt_3_with_nc_for_literal', 'gpt_prompt_3_with_sentence_for_literal']].to_csv('gpt_prompt_responses_2.csv', index=False)\n"
      ],
      "metadata": {
        "id": "fGfokMwFJ0_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deprecated (run specific standalone experiments)"
      ],
      "metadata": {
        "id": "4tYIywyYXLqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Baseline 1: Sentence only"
      ],
      "metadata": {
        "id": "HHui7nG3OjuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline: Full context sentence\n",
        "exp_name = \"Baseline (Sentences)\"\n",
        "\n",
        "print(f\"\\nRunning \\\"{exp_name}\\\" on {len(models)} models...\")\n",
        "for idx, conf in enumerate(models):\n",
        "  print(f\"\\nModel [{idx+1}/{len(models)}]: {conf['model_name']} ({conf['base_model']})\")\n",
        "\n",
        "  metrics, preds, confidence = run_experiment(\n",
        "      model=conf['model'],\n",
        "      processor=conf['preprocess'],\n",
        "      df=df,\n",
        "      image_paths=df['image_paths'],\n",
        "      text_inputs=df['compound'],\n",
        "      model_name=conf['model_name'],\n",
        "      experiment_name=exp_name,\n",
        "      base_model=conf['base_model']\n",
        "  )\n",
        "  save_predictions(\n",
        "      df=df,\n",
        "      image_paths=df['image_paths'],\n",
        "      predictions=preds,\n",
        "      confidence_scores=confidence,\n",
        "      metrics=metrics,\n",
        "      prefix=f\"{conf['base_model']}_{conf['model_name']}_{exp_name.lower()}\"\n",
        "  )"
      ],
      "metadata": {
        "id": "vVHB9rhTpP5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Baseline 2: NC only"
      ],
      "metadata": {
        "id": "i6n4c9bBe_6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Experiment 2: NC-only\n",
        "exp_name = \"NC-Only\"\n",
        "\n",
        "print(f\"\\nRunning \\\"{exp_name}\\\" on {len(models)} models...\")\n",
        "for idx, conf in enumerate(models):\n",
        "  print(f\"\\nModel [{idx+1}/{len(models)}]: {conf['model_name']} ({conf['base_model']})\")\n",
        "\n",
        "  metrics, preds, confidence = run_experiment(\n",
        "      model=conf['model'],\n",
        "      processor=conf['preprocess'],\n",
        "      df=df,\n",
        "      image_paths=df['image_paths'],\n",
        "      text_inputs=df['compound'],\n",
        "      model_name=conf['model_name'],\n",
        "      experiment_name=exp_name,\n",
        "      base_model=conf['base_model']\n",
        "  )\n",
        "  save_predictions(\n",
        "      df=df,\n",
        "      image_paths=df['image_paths'],\n",
        "      predictions=preds,\n",
        "      confidence_scores=confidence,\n",
        "      metrics=metrics,\n",
        "      prefix=f\"{conf['base_model']}_{conf['model_name']}_{exp_name}\"\n",
        "  )"
      ],
      "metadata": {
        "id": "gcpxdPCyp6P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run Experiment 3"
      ],
      "metadata": {
        "id": "6s2KxV54fG5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2: NC-only\n",
        "exp_name = \"GPT Prompt 1\"\n",
        "\n",
        "print(f\"\\nRunning \\\"{exp_name}\\\" on {len(models)} models...\")\n",
        "for idx, conf in enumerate(models):\n",
        "  print(f\"\\nModel [{idx+1}/{len(models)}]: {conf['model_name']} ({conf['base_model']})\")\n",
        "\n",
        "  metrics, preds, confidence = run_experiment(\n",
        "      model=conf['model'],\n",
        "      processor=conf['preprocess'],\n",
        "      df=df,\n",
        "      image_paths=df['image_paths'],\n",
        "      text_inputs=df['compound'],\n",
        "      model_name=conf['model_name'],\n",
        "      experiment_name=exp_name,\n",
        "      base_model=conf['base_model']\n",
        "  )\n",
        "  save_predictions(\n",
        "      df=df,\n",
        "      image_paths=df['image_paths'],\n",
        "      predictions=preds,\n",
        "      confidence_scores=confidence,\n",
        "      metrics=metrics,\n",
        "      prefix=f\"{conf['base_model']}_{conf['model_name']}_{exp_name.lower()}\"\n",
        "  )"
      ],
      "metadata": {
        "id": "hS8i0UiRptum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r results_1751.zip predictions/ experiment_results.csv gpt_prompt_responses_2.csv\n",
        "from google.colab import files\n",
        "files.download('results_1751.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "58cG1UxQfXD1",
        "outputId": "d28d2fee-d75c-4906-d42f-8c89c3d9c456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: predictions/ (stored 0%)\n",
            "  adding: predictions/CLIP_ViT-L14_gpt_prompt_3_with_sentence_for_literal_preds.csv (deflated 64%)\n",
            "  adding: predictions/CLIP_ViT-B32_gpt_prompt_3_preds.csv (deflated 62%)\n",
            "  adding: predictions/CLIP_ViT-B32_gpt_prompt_3_with_nc_for_literal_preds.csv (deflated 62%)\n",
            "  adding: predictions/CLIP_ViT-L14_gpt_prompt_3_with_nc_for_literal_preds.csv (deflated 63%)\n",
            "  adding: predictions/CLIP_ViT-L14_gpt_prompt_3_preds.csv (deflated 63%)\n",
            "  adding: predictions/CLIP_ViT-L14_gpt_prompt_2_preds.csv (deflated 63%)\n",
            "  adding: predictions/Align_Base_gpt_prompt_1_preds.csv (deflated 62%)\n",
            "  adding: predictions/open_clip_ViT-B-32_gpt_prompt_2_preds.csv (deflated 65%)\n",
            "  adding: predictions/Align_Base_gpt_prompt_3_preds.csv (deflated 62%)\n",
            "  adding: predictions/CLIP_ViT-B32_gpt_prompt_3_with_sentence_for_literal_preds.csv (deflated 62%)\n",
            "  adding: predictions/Align_Base_gpt_prompt_3_with_sentence_for_literal_preds.csv (deflated 62%)\n",
            "  adding: predictions/CLIP_RN50x64_gpt_prompt_2_preds.csv (deflated 63%)\n",
            "  adding: predictions/CLIP_RN50x64_gpt_prompt_1_preds.csv (deflated 63%)\n",
            "  adding: predictions/CLIP_RN50x64_gpt_prompt_3_with_sentence_for_literal_preds.csv (deflated 63%)\n",
            "  adding: predictions/CLIP_RN50x64_gpt_prompt_3_preds.csv (deflated 63%)\n",
            "  adding: predictions/Align_Base_gpt_prompt_2_preds.csv (deflated 62%)\n",
            "  adding: predictions/open_clip_ViT-B-32_gpt_prompt_1_preds.csv (deflated 65%)\n",
            "  adding: predictions/CLIP_ViT-B32_gpt_prompt_1_preds.csv (deflated 62%)\n",
            "  adding: predictions/CLIP_RN50x64_gpt_prompt_3_with_nc_for_literal_preds.csv (deflated 63%)\n",
            "  adding: predictions/CLIP_ViT-L14_gpt_prompt_1_preds.csv (deflated 63%)\n",
            "  adding: predictions/open_clip_ViT-B-32_gpt_prompt_3_preds.csv (deflated 64%)\n",
            "  adding: predictions/Align_Base_gpt_prompt_3_with_nc_for_literal_preds.csv (deflated 62%)\n",
            "  adding: predictions/CLIP_ViT-B32_gpt_prompt_2_preds.csv (deflated 62%)\n",
            "  adding: predictions/open_clip_ViT-B-32_gpt_prompt_3_with_nc_for_literal_preds.csv (deflated 65%)\n",
            "  adding: predictions/open_clip_ViT-B-32_gpt_prompt_3_with_sentence_for_literal_preds.csv (deflated 65%)\n",
            "  adding: experiment_results.csv (deflated 79%)\n",
            "  adding: gpt_prompt_responses_2.csv (deflated 69%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e2e08b14-48bb-4ac7-8e26-c9740a31debe\", \"results_1751.zip\", 82881)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}