{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otLzgqFuKy4q"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fgXt-b3SbXu"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "from openai import OpenAI\n",
    "\n",
    "# OpenAI initialization\n",
    "client = OpenAI(api_key=userdata.get('OPENAI_PROJECT_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AH_jK62hida8"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRhSD182jH9b"
   },
   "outputs": [],
   "source": [
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HDvXUFiHn9H"
   },
   "source": [
    "## Data loading and preprocessing\n",
    "select one of extended or test set to continue with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fPmvedoRQVF"
   },
   "source": [
    "##### test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhczzv-RFL_G"
   },
   "outputs": [],
   "source": [
    "file_id = \"1GSw-7lcRmBUiypk3iyskvLLbC5Ip4BrE\" # test\n",
    "file_name = \"taskA_test.zip\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "gdown.download(url, file_name, quiet=True)\n",
    "! unzip -q - taskA_test.zip\n",
    "\n",
    "taska_folder = \"test\"\n",
    "taska_tsv_filename = \"subtask_a_test.tsv\"\n",
    "dataset = \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyOkld0UROzn"
   },
   "source": [
    "#####  uncomment to instead run for extended set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qqy8cEJhRMVI"
   },
   "outputs": [],
   "source": [
    "# file_id = \"1MPD814bn8lktCTJZt2naTQAz02ffjd9l\"\n",
    "# file_name = \"taskA_ext.zip\"\n",
    "# url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "# gdown.download(url, file_name, quiet=True)\n",
    "# ! unzip -q - taskA_ext.zip\n",
    "\n",
    "# taska_folder = \"xeval\"\n",
    "# taska_tsv_filename = \"subtask_a_xe.tsv\"\n",
    "# dataset = \"xe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LksbgUyKGT9T"
   },
   "source": [
    "### Dataframe creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZvNFiadj7Qp"
   },
   "source": [
    "#### initialize df & preprocess image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63HsE3LgHlJy"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{taska_folder}/{taska_tsv_filename}\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmTFg1xmewIb"
   },
   "source": [
    "#### preprocess image paths for ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Iq1ywZfFV0_"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df, dir_name):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the dataset, setting up image paths.\n",
    "    \"\"\"\n",
    "    image_name_cols = ['image1_name', 'image2_name', 'image3_name', 'image4_name', 'image5_name']\n",
    "    df['image_paths'] = df.apply(lambda row: [os.path.join(dir_name, row['compound'].replace(\"'\", \"_\"), row[image_name]) for image_name in image_name_cols], axis=1)\n",
    "    return df\n",
    "\n",
    "df = preprocess_data(df, taska_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ok0L6UJh_wA"
   },
   "source": [
    "## Sentence type classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tilTcFhVJp7u"
   },
   "source": [
    "##### Load saved results\n",
    "For extended dataset only. Instead of querying for new classifications (below), here's some we made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpqA5rsyJsVb"
   },
   "outputs": [],
   "source": [
    "classification_results_file_id = \"1ZWztepcLYrjJu-3iww3MoJDgFPLyZ33C\"\n",
    "classification_results_file_name = \"classification_responses_ext.tsv\"\n",
    "\n",
    "url = f\"https://drive.google.com/uc?id={classification_results_file_id}\"\n",
    "gdown.download(url, classification_results_file_name, quiet=True)\n",
    "\n",
    "classification_df = pd.read_csv(classification_results_file_name, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSQu2M3GLxx5"
   },
   "outputs": [],
   "source": [
    "df['sentence_type_pred'] = classification_df['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nrl3zZgk7iq"
   },
   "source": [
    "##### Define classification prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFKmCTkskj5D"
   },
   "outputs": [],
   "source": [
    "def get_gpt_sentence_types_prompt(samples):\n",
    "  return f\"\"\"\n",
    "You are a linguistics expert specializing in figurative language. You will be given a set of samples, each containing a 'target phrase' paired with a 'context sentence' containing a usage of said phrase.\n",
    "The target phrases all have idiomatic (i.e. figurative) meanings, but they might be used literally in these context sentences!\n",
    "For each sample, you are to do the following:\n",
    "1. Looking at the target phrase in isolation, state its *idiomatic* meaning and its *literal* meaning. The literal meaning might be awkward, as some of these phrases are almost always used idiomatically.\n",
    "2. *Carefully* consider how the target phrase is used in the context sentence. Is it used in its idiomatic sense (in most cases, they way that we're used to understanding it), or is it used as a literal composition of its component words?\n",
    "3. Verbose explanation: Given your familiarity with the phrase's possible meanings, and having considered how it\"s used in the sentence, give an explanation of what the phrase means in the context of the sentence. Remember: if the literal usage is *plausible*, it is probably used literally.\n",
    "4. Final usage determination: Based on steps 1-3, state whether the phrase\"s use in the context sentence is 'literal' or 'idiomatic'.\n",
    "\n",
    "Example input:\n",
    "Target phrase: 'cold turkey'\n",
    "Context sentence: 'John quit smoking cold turkey and never looked back, not that it was easy.'\n",
    "\n",
    "Target phrase: 'ghost town'\n",
    "Context sentence: 'Our wanderings had led us perilously close to the walls of the ghost town where restless spirits haunted the streets, eager to absorb the vitatlity of the living.'\n",
    "\n",
    "---\n",
    "\n",
    "Example response:\n",
    "{{\"data\": [\n",
    "    {{\n",
    "      \"target_phrase\": \"cold turkey\",\n",
    "      \"idiomatic_meaning\": \"To stop a habit or addiction abruptly and completely, without gradually reducing or tapering off. It often refers to ceasing a harmful behavior or substance like smoking or drugs.\",\n",
    "      \"literal_meaning\": \"A turkey that is cold.\"\n",
    "      \"contextual_considerations\": \"In the sentence, 'John quit smoking cold turkey and never looked back, not that it was easy,' the phrase 'cold turkey' clearly does not refer to food. It is used in the context of quitting smoking, which aligns with the idiomatic usage of the term.\",\n",
    "      \"verbose_explanation\": \"The phrase 'cold turkey' in this sentence means that John abruptly stopped smoking without tapering off or using substitutes like nicotine patches. The description highlights the difficulty of this approach, suggesting that quitting 'cold turkey' was challenging but ultimately successful. The context does not mention anything about literal turkey, further affirming the idiomatic interpretation.\",\n",
    "      \"result\": \"idiomatic\"\n",
    "    }},\n",
    "    {{\n",
    "      \"target_phrase\": \"ghost town\",\n",
    "      \"idiomatic_meaning\": \"A deserted town or settlement that was once populated but is now abandoned, often evoking a sense of desolation or emptiness.\",\n",
    "      \"literal_meaning\": \"A town inhabited by ghosts or supernatural entities, as in fictional or mythological contexts.\"\n",
    "      \"contextual_considerations\": \"In the sentence, 'Our wanderings had led us perilously close to the walls of the ghost town where restless spirits haunted the streets, eager to absorb the vitality of the living,' the description explicitly mentions 'restless spirits' and their interaction with the living. This strongly suggests a literal interpretation involving supernatural elements.\",\n",
    "      \"verbose_explanation\": \"Here, 'ghost town' refers to a literal place inhabited by ghosts or spirits, as indicated by the detailed imagery of 'restless spirits' and their haunting presence. The context does not suggest the metaphorical use of the term as an abandoned, non-supernatural settlement.\",\n",
    "      \"result\": \"literal\"\n",
    "    }}\n",
    "]}}\n",
    "\n",
    "---\n",
    "\n",
    "You must return a valid JSON object formatted exactly as follows:\n",
    "- Do not use double-quotes inside of JSON values. If quotes are necessary, use single-quotes.\n",
    "- Do not include line breaks inside JSON values.\n",
    "- Strictly follow the schema:\n",
    "\n",
    "Output JSON schema:\n",
    "{{\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {{\n",
    "    \"data\": {{\n",
    "      \"type\": \"array\",\n",
    "      \"items\": {{\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {{\n",
    "          \"target_phrase\": {{\"type\": \"string\"}},\n",
    "          \"idiomatic_meaning\": {{\"type\": \"string\"}},\n",
    "          \"literal_meaning\": {{\"type\": \"string\"}},\n",
    "          \"contextual_considerations\": {{\"type\": \"string\"}},\n",
    "          \"verbose_explanation\": {{\"type\": \"string\"}},\n",
    "          \"result\": {{\"type\": \"string\", \"enum\": [\"idiomatic\", \"literal\"]}}\n",
    "        }},\n",
    "        \"required\": [\"target_phrase\", \"idiomatic_meaning\", \"literal_meaning\", \"contextual_considerations\", \"verbose_explanation\", \"result\"]\n",
    "      }}\n",
    "    }}\n",
    "  }},\n",
    "  \"required\": [\"data\"]\n",
    "}}\n",
    "\n",
    "Ensure the response is a **valid** JSON object with escaped quotes.\n",
    "DO NOT include extra commentary.\n",
    "\n",
    "Your turn. These are the samples:\n",
    "{samples}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWR1lpndqwHk"
   },
   "source": [
    "##### Define prompting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99DYyJWZSV2-"
   },
   "outputs": [],
   "source": [
    "def gpt_sentence_types(compounds, sentences):\n",
    "    \"\"\"\n",
    "    Prompt GPT-4 to get the sentence type, literal or figurative, for a batch of sentences.\n",
    "    \"\"\"\n",
    "    # Create a combined prompt\n",
    "    samples = \"\\n\\n\".join([\n",
    "        f'Target phrase: \"{nc}\"\\nContext sentence: \"{sentence}\"' for nc, sentence in zip(compounds, sentences)\n",
    "    ])\n",
    "\n",
    "    prompt = get_gpt_sentence_types_prompt(samples)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "    try:\n",
    "        raw_content = response.choices[0].message.content.strip()\n",
    "        content = json.loads(raw_content)\n",
    "        # print(\"Raw response content:\")\n",
    "        # print(json.dumps(content, indent=4))  # Debug formatted output\n",
    "        return content\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decoding error: {e}\")\n",
    "        print(\"Response content that caused error:\", raw_content)\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZchmZEGlGsr"
   },
   "source": [
    "##### Get classification responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgf9fHdboq0N"
   },
   "outputs": [],
   "source": [
    "# Run sentence type classifier in batches\n",
    "def run_classification(df, batch_size):\n",
    "    all_samples = []\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        print(f\"\\nStarting batch: {i}-{i+batch_size-1}\")\n",
    "\n",
    "        batch = df.iloc[i:i + batch_size]\n",
    "        responses = gpt_sentence_types(batch['compound'].tolist(),\n",
    "                                       batch['sentence'].tolist())\n",
    "\n",
    "        if \"data\" in responses:\n",
    "            all_samples.extend(responses[\"data\"])\n",
    "        else:\n",
    "            print(f\"Warning: No 'data' key in response for batch {i}-{i+batch_size-1}\")\n",
    "\n",
    "    return all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "kGpQ7X_PkJF6"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    run_idx = i+1\n",
    "    print(f\"\\n\\nStarting run #{run_idx}\")\n",
    "    classification_responses = run_classification(df, 20)\n",
    "    print(f\"Run #{run_idx} -- Total samples collected: {len(classification_responses)}\")\n",
    "    classification_responses_df = pd.DataFrame(classification_responses)\n",
    "    cls_filename = f\"{dataset}_classification_responses_{run_idx}.tsv\"\n",
    "    classification_responses_df.to_csv(cls_filename, sep='\\t', index=False)\n",
    "    print(f\"Downloading file: {cls_filename}\")\n",
    "    files.download(cls_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1Minc9mDZ0d"
   },
   "source": [
    "#### classification voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpwkkX9eDdLH"
   },
   "outputs": [],
   "source": [
    "df_cls_1 = pd.read_csv(f\"{dataset}_classification_responses_1.tsv\", delimiter=\"\\t\")\n",
    "df_cls_2 = pd.read_csv(f\"{dataset}_classification_responses_2.tsv\", delimiter=\"\\t\")\n",
    "df_cls_3 = pd.read_csv(f\"{dataset}_classification_responses_3.tsv\", delimiter=\"\\t\")\n",
    "df_cls_4 = pd.read_csv(f\"{dataset}_classification_responses_4.tsv\", delimiter=\"\\t\")\n",
    "df_cls_5 = pd.read_csv(f\"{dataset}_classification_responses_5.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKqDs9dJFL7b"
   },
   "outputs": [],
   "source": [
    "cls_dfs = [df_cls_1, df_cls_2, df_cls_3, df_cls_4, df_cls_5]\n",
    "\n",
    "df_voting = df['compound'].to_frame()\n",
    "\n",
    "for i, df_cls in enumerate(cls_dfs, start=1):\n",
    "    df_cls.rename(columns={'result': f'result_{i}'}, inplace=True)\n",
    "    df_voting = df_voting.merge(df_cls[['target_phrase', f'result_{i}']],\n",
    "              left_on='compound',\n",
    "              right_on='target_phrase',\n",
    "              how='left')\n",
    "    df_voting.drop(columns=['target_phrase'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3LO81iBfGbS"
   },
   "outputs": [],
   "source": [
    "def vote(row):\n",
    "    results = row[['result_1', 'result_2', 'result_3', 'result_4', 'result_5']]\n",
    "\n",
    "    valid_results = results[results.isin(['idiomatic', 'literal'])]\n",
    "\n",
    "    counts = valid_results.value_counts()\n",
    "    idiomatic_count = counts.get('idiomatic', 0)\n",
    "    literal_count   = counts.get('literal', 0)\n",
    "\n",
    "    if idiomatic_count > literal_count:\n",
    "        return 'idiomatic'\n",
    "    elif literal_count > idiomatic_count:\n",
    "        return 'literal'\n",
    "    else:\n",
    "        # return 'tie'\n",
    "        return 'literal' # break the tie\n",
    "\n",
    "df_voting['final_result'] = df_voting.apply(vote, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-R5RVcpGIuj"
   },
   "outputs": [],
   "source": [
    "# add classification result to main df\n",
    "df['sentence_type_pred'] = df_voting['final_result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sq34SmwTh5Cs"
   },
   "source": [
    "## Idiom definitions for text input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2jw8BOPU4fs"
   },
   "source": [
    "##### Load stored responses\n",
    "For extended dataset only. Instead of generating new definitions (below), here's some we made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDEKGIhuU6jf"
   },
   "outputs": [],
   "source": [
    "def_responses_file_id = \"1fOZu7wA14JtSoKPF9L2g2ODyoXzPqbv9\"\n",
    "def_responses_file_name = \"idiom_definitions.csv\"\n",
    "\n",
    "url = f\"https://drive.google.com/uc?id={def_responses_file_id}\"\n",
    "gdown.download(url, def_responses_file_name, quiet=True)\n",
    "defs_df = pd.read_csv(def_responses_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z04dT3uaLxrx"
   },
   "outputs": [],
   "source": [
    "# merge defs_df into df on defs_df['target_phrase'] == df['compound']\n",
    "df = df.merge(defs_df[['target_phrase', 'result']],\n",
    "              left_on='compound',\n",
    "              right_on='target_phrase',\n",
    "              how='left').rename(columns={'result': 'idiom_def'}).drop(columns=['target_phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zqW5POWM-81"
   },
   "outputs": [],
   "source": [
    "# fill nan with compound\n",
    "df['text_input'] = df.apply(lambda x: x['idiom_def'] if x['idiom_def'] == x['idiom_def'] else x['compound'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PWnEH4inai-"
   },
   "source": [
    "### Define prompts and get definitions\n",
    "use **either** prompt 1 or prompt 2 to generate definitions for idiomatic sentences (if not loading existing definitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xD5Wb-cofBwC"
   },
   "outputs": [],
   "source": [
    "def gpt_definitions(compounds, sentence_types, base_prompt):\n",
    "    \"\"\"\n",
    "    Generate definitions for target phrases using GPT-4, in batches.\n",
    "    \"\"\"\n",
    "\n",
    "    input_data = [\n",
    "        nc for nc, sentence_type in zip(compounds, sentence_types)\n",
    "    ]\n",
    "\n",
    "    # Create a combined prompt\n",
    "    examples = \"\\n\".join([\n",
    "        f'The idiom is: \"{nc}\".' for nc in input_data\n",
    "    ])\n",
    "    # print(f\"examples:\\n{examples}\")\n",
    "\n",
    "    prompt = base_prompt + examples\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "    try:\n",
    "        raw_content = response.choices[0].message.content.strip()\n",
    "        content = json.loads(raw_content)\n",
    "        # print(json.dumps(content, indent=4))  # Debug formatted output\n",
    "        return content\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decoding error: {e}\")\n",
    "        print(\"Response content that caused error:\", raw_content)\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1wqtvKsx50B"
   },
   "source": [
    "#### prompt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNYzqpEFn1zJ"
   },
   "outputs": [],
   "source": [
    "prompt_exp6_idiomatic = f\"\"\"\n",
    "You are a linguistics expert specializing in idioms. You will be given a set of idioms to process. For each one, do the following steps aloud (in writing):\n",
    "1. Give a verbose explanation of the idiom, including what connotations it carries or undertones it evokes.\n",
    "2. Give a definition of the *literal* meaning of the phrase. For noun phrases representing physical objects, focus on unambiguous visual descriptors.\n",
    "3. Taking into consideration your response for #1 and #2, list three potential definitions, no longer than 20 words each, that capture the **core emotional or situational essence** conveyed by the idiom. Use **simple language that an average high-schooler would understand** and avoid figurative or overly abstract language. Focus on clear, visually interpretable descriptions that are distinct from the literal definition.\n",
    "4. Choose the best definition.\n",
    "\n",
    "---\n",
    "\n",
    "Example outputs:\n",
    "{{\n",
    "  \"data\": [\n",
    "    {{\n",
    "      \"target_phrase\": \"glass ceiling\",\n",
    "      \"explanation\": \"Refers to an invisible barrier that prevents certain groups, often women or minorities, from advancing in their careers or social positions. Evokes frustration, inequality, and hidden obstacles. Frequently used in discussions of systemic discrimination.\",\n",
    "      \"literal_definition\": \"A ceiling made of transparent glass.\",\n",
    "      \"potential_definition_1\": \"A hidden obstacle that blocks people from reaching higher positions.\",\n",
    "      \"potential_definition_2\": \"An unseen barrier that stops progress for qualified individuals.\",\n",
    "      \"potential_definition_3\": \"A quiet limit that keeps certain groups from moving upward.\",\n",
    "      \"result\": \"A hidden obstacle that blocks people from reaching higher positions.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"target_phrase\": \"missing link\",\n",
    "      \"explanation\": \"Suggests a crucial piece of information or evidence needed to bridge a gap in knowledge or understanding. Evokes the sense of an incomplete puzzle, emphasizing the importance of finding what’s absent.\",\n",
    "      \"literal_definition\": \"A link in a chain that is not present, creating a gap.\",\n",
    "      \"potential_definition_1\": \"A key piece that completes an unfinished idea or puzzle.\",\n",
    "      \"potential_definition_2\": \"Something crucial that holds everything together but is absent.\",\n",
    "      \"potential_definition_3\": \"An important connecting factor that is missing or unknown.\",\n",
    "      \"result\": \"A key piece that completes an unfinished idea or puzzle.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"target_phrase\": \"paper tiger\",\n",
    "      \"explanation\": \"Describes someone or something that appears threatening or powerful but is actually weak or ineffective. Connotes empty threats or superficial strength.\",\n",
    "      \"literal_definition\": \"A tiger made of paper, such as origami or a paper figure.\",\n",
    "      \"potential_definition_1\": \"Something that seems strong but has little real power.\",\n",
    "      \"potential_definition_2\": \"A fragile threat that looks more dangerous than it is.\",\n",
    "      \"potential_definition_3\": \"A force that seems scary but collapses under pressure.\",\n",
    "      \"result\": \"Something that seems strong but has little real power.\"\n",
    "    }}\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "\n",
    "---\n",
    "\n",
    "You must return a valid JSON object:\n",
    "- Do not use double quotes inside your value strings.\n",
    "- Do not include line breaks inside JSON values.\n",
    "- Strictly follow the schema.\n",
    "\n",
    "Schema:\n",
    "{{\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {{\n",
    "    \"data\": {{\n",
    "      \"type\": \"array\",\n",
    "      \"items\": {{\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {{\n",
    "          \"target_phrase\": {{ \"type\": \"string\" }},\n",
    "          \"explanation\": {{ \"type\": \"string\" }},\n",
    "          \"literal_definition\": {{ \"type\": \"string\" }},\n",
    "          \"potential_definition_1\": {{ \"type\": \"string\" }},\n",
    "          \"potential_definition_2\": {{ \"type\": \"string\" }},\n",
    "          \"potential_definition_3\": {{ \"type\": \"string\" }},\n",
    "          \"result\": {{ \"type\": \"string\" }}\n",
    "        }},\n",
    "        \"required\": [\"target_phrase\", \"explanation\", \"potential_definition_1\", \"potential_definition_2\", \"potential_definition_3\", \"result\"]\n",
    "      }}\n",
    "    }}\n",
    "  }},\n",
    "  \"required\": [\"data\"]\n",
    "}}\n",
    "\n",
    "Ensure the response is a valid JSON object with escaped quotes.\n",
    "\n",
    "Here are the samples:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "HxKADFwn9ASD"
   },
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "all_data = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    print(f\"\\n Starting batch: {i}-{i+batch_size-1}\")\n",
    "    batch = df.iloc[i:i + batch_size]\n",
    "    responses = gpt_definitions(batch['compound'].tolist(),\n",
    "                                batch['sentence_type_pred'].tolist(),\n",
    "                                prompt_exp6_idiomatic)\n",
    "\n",
    "    if \"data\" in responses:\n",
    "        all_data.extend(responses[\"data\"])\n",
    "        print(f\"len(all_data): {len(all_data)}\")\n",
    "    else:\n",
    "        print(f\"Warning: no 'data' in response for batch {i}-{i+batch_size-1}\")\n",
    "\n",
    "df_exp6_defs_idiomatic = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCX0MPcSOGeI"
   },
   "outputs": [],
   "source": [
    "df_exp6_defs_idiomatic.to_csv(f\"{dataset}_exp6_definitions_idiomatic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVJENA8cv8TD"
   },
   "outputs": [],
   "source": [
    "files.download(f\"{dataset}_exp6_definitions_idiomatic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dh3m9CgKxjih"
   },
   "outputs": [],
   "source": [
    "# merge defs_df into df on defs_df['target_phrase'] == df['compound']\n",
    "df = df.merge(df_exp6_defs_idiomatic[['target_phrase', 'result']],\n",
    "              left_on='compound',\n",
    "              right_on='target_phrase',\n",
    "              how='left').rename(columns={'result': 'idiom_def'}).drop(columns=['target_phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IAyEY6Dxjii"
   },
   "outputs": [],
   "source": [
    "df['text_input'] = df.apply(lambda x: x['idiom_def'] if x['sentence_type_pred'] == 'idiomatic' else x['compound'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVXzV5YpZJyL"
   },
   "source": [
    "#### prompt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2c41UT_N0sRW"
   },
   "outputs": [],
   "source": [
    "prompt_exp7_idiomatic = \"\"\"\"\n",
    "You are a linguistics and visual storytelling expert, with an expertise on differentiating idiomatic from literal language. For each sample idiom below, your task is to create visual and textual representations that align well with the idiom’s figurative meaning for use in matching with images. Follow these steps:\n",
    "\n",
    "1. Identify the phrase: Give a concise definition of the phrase in its idiomatic sense.\n",
    "2. Note the literal usage (briefly): Mention the plain or surface meaning, but clarify that you are focusing on the figurative interpretation for your examples.\n",
    "3. Generate 5 distinct image ideas: For the given idiom, imagine 5 different scenes or situations that visually depict its figurative meaning. Describe each scene in 1-2 sentences, focusing on visual details.\n",
    "4. Generalize the captions: Write a single caption that could apply to all 5 scenes. It should capture the essence of the idiom in a way that is broad enough to fit any of the scenes.\n",
    "5. Refine: Reflect on how well your caption generalizes to all five scenes, then attempt to improve on it.\n",
    "6. Consider which caption is best: Weigh the captions against each other, then pick the one that best fits all 5 scenes.\n",
    "7. Select the best caption: Repeat the caption you selected.\n",
    "\n",
    "---\n",
    "\n",
    "Example outputs:\n",
    "{\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"target_phrase\": \"glass ceiling\",\n",
    "      \"explanation\": \"Refers to an invisible barrier that prevents certain groups (often women or minorities) from advancing to higher levels of power or responsibility. Implies a hidden form of discrimination that is not overtly acknowledged but still limits upward mobility.\",\n",
    "      \"literal_definition\": \"A ceiling made of glass.\",\n",
    "      \"image_ideas\": [\n",
    "        \"A businesswoman standing just below a transparent barrier in a large corporate office, looking up at executives in the floor above.\",\n",
    "        \"A group of female or minority employees reaching a fancy mezzanine level only to find an unseen barrier between them and the boardroom.\",\n",
    "        \"A symbolic representation of cracks forming in a transparent barrier overhead as a woman holds a briefcase, showing determination to break through.\",\n",
    "        \"A silhouette of a person pressed against a clear pane, with a hand raised as though trying to push past it.\",\n",
    "        \"A visually layered office setting, where higher floors are accessible but separated by a nearly invisible division, highlighting the subtlety of the barrier.\"\n",
    "      ],\n",
    "      \"generalized_caption_1\": \"Facing an unseen barrier to advancement.\",\n",
    "      \"generalized_caption_2\": \"Pushing against a hidden boundary in pursuit of progress.\",\n",
    "      \"thinking\": \"Both captions address the concept of a hidden obstruction. The second one, 'Pushing against a hidden boundary in pursuit of progress,' suggests active resistance and forward motion, which suits the idiom’s connotation of striving to break through.\",\n",
    "      \"result\": \"Pushing against a hidden boundary in pursuit of progress.\"\n",
    "    },\n",
    "    {\n",
    "      \"target_phrase\": \"paper tiger\",\n",
    "      \"explanation\": \"Describes someone or something that appears threatening or powerful but is actually weak or ineffectual. Connotes false bravado or an overestimation of strength.\",\n",
    "      \"literal_definition\": \"A tiger made out of paper.\",\n",
    "      \"image_ideas\": [\n",
    "        \"A large, menacing figure looming over a crowd, only to be revealed as hollow or easily torn.\",\n",
    "        \"A roaring tiger image on a billboard that looks scary but is just thin paper peeling at the edges.\",\n",
    "        \"A towering cardboard cutout of a tiger in a political rally, symbolizing empty threats or exaggerated power.\",\n",
    "        \"A fierce-looking trophy made of paper mache, displayed in a spotlight to highlight its fragile nature.\",\n",
    "        \"An intimidating sign with a tiger illustration in front of a building, but the sign is tattered and flapping in the wind, showing its vulnerability.\"\n",
    "      ],\n",
    "      \"generalized_caption_1\": \"A formidable appearance that masks a fragile reality.\",\n",
    "      \"generalized_caption_2\": \"Something that looks strong but lacks real power.\",\n",
    "      \"thinking\": \"The second caption directly addresses the core meaning—'Something that looks strong but lacks real power.' It's concise and precise.\",\n",
    "      \"result\": \"Something that looks strong but lacks real power.\"\n",
    "    },\n",
    "    {\n",
    "      \"target_phrase\": \"missing link\",\n",
    "      \"explanation\": \"Refers to a crucial piece of information or element that helps connect different ideas, theories, or facts. Connotes something vital that completes a puzzle or fills a gap in understanding.\",\n",
    "      \"literal_definition\": \"A link in a chain (like a ring or segment) that is absent.\",\n",
    "      \"image_ideas\": [\n",
    "        \"A detective at a crime board tapping a blank space among photos and clues, indicating a vital piece of evidence that’s not yet found.\",\n",
    "        \"An evolutionary chart with a silhouette in the middle missing, leaving a gap in the progression from ape to human.\",\n",
    "        \"A jigsaw puzzle nearly completed, except for a conspicuously empty spot in the center.\",\n",
    "        \"A timeline pinned on a wall with a significant date missing, highlighting the gap in recorded history.\",\n",
    "        \"A scientific lab setting where a researcher stands before a half-finished hypothesis, gazing at a large question mark on the board.\"\n",
    "      ],\n",
    "      \"generalized_caption_1\": \"A crucial piece that completes the bigger picture.\",\n",
    "      \"generalized_caption_2\": \"The vital connecting factor that brings everything together.\",\n",
    "      \"thinking\": \"Between the two, 'A crucial piece that completes the bigger picture' fits the notion of something vital and absent, capturing the idiomatic essence succinctly.\",\n",
    "      \"result\": \"A crucial piece that completes the bigger picture.\"\n",
    "    }\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "You must return a valid JSON object:\n",
    "- Do not use double quotes inside your value strings.\n",
    "- Do not include line breaks inside JSON values.\n",
    "- Strictly follow the schema.\n",
    "\n",
    "Schema:\n",
    "{\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"data\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"target_phrase\": { \"type\": \"string\" },\n",
    "          \"explanation\": { \"type\": \"string\" },\n",
    "          \"literal_definition\": { \"type\": \"string\" },\n",
    "          \"image_ideas\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n",
    "          \"generalized_caption_1\": { \"type\": \"string\" },\n",
    "          \"generalized_caption_2\": { \"type\": \"string\" },\n",
    "          \"thinking\": { \"type\": \"string\" },\n",
    "          \"result\": { \"type\": \"string\" }\n",
    "        },\n",
    "        \"required\": [\"target_phrase\", \"image_ideas\", \"generalized_caption_1\", \"generalized_caption_2\", \"thinking\", \"result\"]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"data\"]\n",
    "}\n",
    "\n",
    "Ensure the response is a valid JSON object with properly escaped quotes.\n",
    "\n",
    "Your turn. Here are the samples:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYC66S3qgS6o"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "all_data = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    print(f\"Starting batch {i}-{i+batch_size-1}...\")\n",
    "\n",
    "    batch = df.iloc[i:i + batch_size]\n",
    "    responses = gpt_definitions(batch['compound'].tolist(),\n",
    "                                batch['sentence_type_pred'].tolist(),\n",
    "                                prompt_exp7_idiomatic)\n",
    "\n",
    "    if \"data\" in responses:\n",
    "        all_data.extend(responses[\"data\"])\n",
    "        print(f\"all_data now has length: {len(all_data)}\")\n",
    "    else:\n",
    "        print(f\"Warning: no 'data' in response for batch {i}-{i+batch_size-1}\")\n",
    "\n",
    "df_exp7_defs_idiomatic = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHTeq2uAkR17"
   },
   "outputs": [],
   "source": [
    "df_exp7_defs_idiomatic.to_csv(f'{dataset}_exp7_definitions_idiomatic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mR4mUjmD_Diw"
   },
   "outputs": [],
   "source": [
    "files.download(f\"{dataset}_exp7_definitions_idiomatic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ciheuCGyaLC"
   },
   "outputs": [],
   "source": [
    "# merge defs_df into df on defs_df['target_phrase'] == df['compound']\n",
    "df = df.merge(df_exp7_defs_idiomatic[['target_phrase', 'result']],\n",
    "              left_on='compound',\n",
    "              right_on='target_phrase',\n",
    "              how='left').rename(columns={'result': 'idiom_def'}).drop(columns=['target_phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCW7cnzUyaLC"
   },
   "outputs": [],
   "source": [
    "df['text_input'] = df.apply(lambda x: x['idiom_def'] if x['sentence_type_pred'] == 'idiomatic' else x['compound'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyEdNn6Znddp"
   },
   "source": [
    "### Run prompts on GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iszmXl5kqTxr"
   },
   "source": [
    "### handle GPT responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBk9arxN2X9n"
   },
   "outputs": [],
   "source": [
    "# Merge all batches into a single DataFrame\n",
    "if all_responses:\n",
    "    response_df = pd.concat(all_responses, ignore_index=True)\n",
    "    response_df.rename(columns={\"result\": \"idiom_def\"}, inplace=True)\n",
    "\n",
    "    # Merge 'text_input' and additional definition columns back into main DataFrame\n",
    "    df = df.merge(response_df[['target_phrase', 'idiom_def', 'generalized_caption_1', 'generalized_caption_2', 'generalized_caption_3']],\n",
    "                  left_on='compound',\n",
    "                  right_on='target_phrase',\n",
    "                  how='left')\n",
    "\n",
    "    # Drop 'target_phrase' since it's redundant after merging\n",
    "    df.drop(columns=['target_phrase'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHFQSJlVGCQE"
   },
   "source": [
    "## Multimodal model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IDOr4CkJ2KN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from ast import literal_eval\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C-URQw2uOhh"
   },
   "source": [
    "#### OpenCLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EDdK_ivzaQ2"
   },
   "outputs": [],
   "source": [
    "!pip install open_clip_torch\n",
    "import open_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "xx4nxTbUFvvN"
   },
   "outputs": [],
   "source": [
    "# define model config\n",
    "openclip_model_version = \"ViT-B-32\"\n",
    "model_openclip, _, preprocess_openclip = open_clip.create_model_and_transforms(openclip_model_version, pretrained='laion2b_s34b_b79k')\n",
    "model_openclip.to(device)\n",
    "open_clip_tokenizer = open_clip.get_tokenizer(openclip_model_version)\n",
    "model_openclip.eval()  # model in train mode by default, impacts some models with BatchNorm or stochastic depth active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mS8JKUsuFdp-"
   },
   "outputs": [],
   "source": [
    "def openclip_image_ranking(model, image_processor, tokenizer, image_paths, sentence):\n",
    "    image_inputs = torch.stack([preprocess_openclip(Image.open(ipath)) for ipath in image_paths]).to(device)\n",
    "    text_input = tokenizer([sentence]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_inputs)\n",
    "        text_features = model.encode_text(text_input)\n",
    "\n",
    "    # normalise features\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # dot product & softmax\n",
    "    similarity = (100.0 * text_features @ image_features.T).softmax(dim=-1)\n",
    "\n",
    "    # order by similarity\n",
    "    probs, indices = similarity[0].topk(5)\n",
    "    return probs, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeWcJp0LFX3n"
   },
   "source": [
    "#### CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xcfEa1tKpe-"
   },
   "outputs": [],
   "source": [
    "# install clip\n",
    "!pip install -q ftfy regex tqdm\n",
    "!pip install -q git+https://github.com/openai/CLIP.git\n",
    "\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGdxPA8VFZaR"
   },
   "outputs": [],
   "source": [
    "def get_image_ranking_clip(model, image_processor, image_paths, sentence):\n",
    "    image_inputs = torch.stack([image_processor(Image.open(ipath)) for ipath in image_paths]).to(device)\n",
    "    text_input = clip.tokenize(sentence).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # compute embeddings\n",
    "        image_features = model.encode_image(image_inputs)\n",
    "        text_features = model.encode_text(text_input)\n",
    "\n",
    "    # normalize features\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # compute similarity scores\n",
    "    similarity = (100.0 * text_features @ image_features.T).softmax(dim=-1)\n",
    "\n",
    "    # rank images by similarity\n",
    "    probs, indices = similarity[0].topk(5)\n",
    "    return probs, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2OA3YQWuUxd"
   },
   "source": [
    "#### ALIGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_t5V5UHzpBS"
   },
   "outputs": [],
   "source": [
    "from transformers import AlignProcessor, AlignModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8r6vF8LwFIX"
   },
   "outputs": [],
   "source": [
    "def get_image_ranking_align(model, processor, image_paths, sentence):\n",
    "    image_inputs = [Image.open(ipath) for ipath in image_paths]\n",
    "    inputs = processor(images=image_inputs ,text=sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits_per_text = outputs.logits_per_text[0]\n",
    "    probs = logits_per_text.softmax(dim=-1)\n",
    "    ids_sorted = torch.argsort(probs, descending=True)\n",
    "    return probs[ids_sorted], ids_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yUbe3LywWBs"
   },
   "source": [
    "### Define model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXnWxnl6vyHZ"
   },
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "    {\n",
    "        \"base_model\": \"CLIP\",\n",
    "        \"model_name\": \"ViT-B/32\",\n",
    "        \"display_name\": \"CLIP1\",\n",
    "        \"model\": clip.load(\"ViT-B/32\", device)[0],\n",
    "        \"preprocess\": clip.load(\"ViT-B/32\", device)[1]\n",
    "    },\n",
    "    {\n",
    "        \"base_model\": \"CLIP\",\n",
    "        \"model_name\": \"ViT-L/14\",\n",
    "        \"display_name\": \"CLIP2\",\n",
    "        \"model\": clip.load(\"ViT-L/14\", device)[0],\n",
    "        \"preprocess\": clip.load(\"ViT-L/14\", device)[1]\n",
    "    },\n",
    "    {\n",
    "        \"base_model\": \"CLIP\",\n",
    "        \"model_name\": \"RN50x64\",\n",
    "        \"display_name\": \"CLIP3\",\n",
    "        \"model\": clip.load(\"RN50x64\", device)[0],\n",
    "        \"preprocess\": clip.load(\"RN50x64\", device)[1]\n",
    "    },\n",
    "    {\n",
    "        \"base_model\": \"Align\",\n",
    "        \"model_name\": \"Base\",\n",
    "        \"display_name\": \"Align\",\n",
    "        \"model\": AlignModel.from_pretrained(\"kakaobrain/align-base\"),\n",
    "        \"preprocess\": AlignProcessor.from_pretrained(\"kakaobrain/align-base\")\n",
    "    },\n",
    "    {\n",
    "        \"base_model\": \"open_clip\",\n",
    "        \"model_name\": openclip_model_version,\n",
    "        \"display_name\": \"openclip\",\n",
    "        \"model\": model_openclip,\n",
    "        \"preprocess\": preprocess_openclip,\n",
    "        \"tokenizer\": open_clip_tokenizer,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W54dAQtNsikZ"
   },
   "source": [
    "### Define inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRAFMw6-JbcT"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, processor, image_paths_list, text_inputs, base_model, model_name, tokenizer=None, model_display_name=None):\n",
    "    \"\"\"\n",
    "    Uses get_image_ranking to generate predictions and confidence scores for a image-list, text-input pairs\n",
    "    \"\"\"\n",
    "    print(f\"get_predictions for {model_display_name}\")\n",
    "    predictions, confidence_scores = [], []\n",
    "\n",
    "    for ipaths, text in zip(image_paths_list, text_inputs):\n",
    "        if len(ipaths) == 0:\n",
    "            predictions.append([])\n",
    "            confidence_scores.append([])\n",
    "            continue\n",
    "\n",
    "        if base_model == \"CLIP\":\n",
    "          values, indices = get_image_ranking_clip(model, processor, ipaths, text)\n",
    "        elif base_model == \"Align\":\n",
    "          values, indices = get_image_ranking_align(model, processor, ipaths, text)\n",
    "        elif base_model == \"open_clip\":\n",
    "          values, indices = openclip_image_ranking(model, processor, tokenizer, ipaths, text)\n",
    "        else:\n",
    "          raise ValueError(f\"Unknown base_model: {base_model}\")\n",
    "        predictions.append(list(indices.cpu()))\n",
    "        confidence_scores.append(100 * values)\n",
    "\n",
    "    return predictions, confidence_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44IPMJvvni9f"
   },
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eS_54QdsJ3US"
   },
   "outputs": [],
   "source": [
    "def run_experiment(model_config):\n",
    "    # get predictions on images\n",
    "    predictions, confidence_scores = get_predictions(\n",
    "        model=model_config['model'],\n",
    "        processor=model_config['preprocess'],\n",
    "        image_paths_list=df['image_paths'],\n",
    "        text_inputs=df['text_input'],\n",
    "        base_model=model_config['base_model'],\n",
    "        model_name=model_config['model_name'],\n",
    "        tokenizer=open_clip_tokenizer,\n",
    "        model_display_name=model_config['display_name']\n",
    "    )\n",
    "    print(f\"Done ({len(predictions)} predictions)\")\n",
    "\n",
    "    # format results\n",
    "    ranked_data = [\n",
    "        {\n",
    "            \"compound\": df[\"compound\"].iloc[i],\n",
    "            \"expected_order\": [os.path.basename(df[\"image_paths\"].iloc[i][j]) for j in pred],\n",
    "            \"confidence_scores\": [f\"{x:.3f}\" for x in conf]\n",
    "        }\n",
    "        for i, (pred, conf) in enumerate(zip(predictions, confidence_scores))\n",
    "    ]\n",
    "    ranked_df = pd.DataFrame(ranked_data)\n",
    "    return ranked_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3s4wwSK9BVXb"
   },
   "outputs": [],
   "source": [
    "for model_config in model_configs:\n",
    "    print(f\"Running model: {model_config['display_name']}\")\n",
    "    ranked_df = run_experiment(model_config)\n",
    "\n",
    "    # write out\n",
    "    filename = f\"{dataset}_{model_config['display_name']}.csv\"\n",
    "    ranked_df.to_csv(filename)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "otLzgqFuKy4q",
    "9HDvXUFiHn9H",
    "0ok0L6UJh_wA",
    "tilTcFhVJp7u",
    "2nrl3zZgk7iq",
    "jWR1lpndqwHk",
    "nZchmZEGlGsr",
    "h1Minc9mDZ0d",
    "sq34SmwTh5Cs",
    "O2jw8BOPU4fs",
    "2PWnEH4inai-",
    "xHFQSJlVGCQE",
    "3C-URQw2uOhh",
    "NeWcJp0LFX3n",
    "o2OA3YQWuUxd",
    "-yUbe3LywWBs",
    "W54dAQtNsikZ",
    "44IPMJvvni9f"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
