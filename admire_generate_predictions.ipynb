{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyP4Tm8ci781wesh451gITzL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f66ed17473c4433ae9f92a2d92271ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91d80297ba3b4a6a99937ad1b6249dad",
              "IPY_MODEL_efccf5a62ef8474ea8b786ee5f86bf65",
              "IPY_MODEL_f80bb9147f6a4517afe4bc4a73d9275b"
            ],
            "layout": "IPY_MODEL_094b3e5b9e9b427f8d5bed37821650f9"
          }
        },
        "91d80297ba3b4a6a99937ad1b6249dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efdf67b16312464c821a0763e6a7832f",
            "placeholder": "​",
            "style": "IPY_MODEL_97b46f71718645219064b9b3883ee178",
            "value": "open_clip_pytorch_model.bin: 100%"
          }
        },
        "efccf5a62ef8474ea8b786ee5f86bf65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eae1bc5070464391a343ddafb28d5ba9",
            "max": 605219813,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54320831424f496ea4b32e86d706f536",
            "value": 605219813
          }
        },
        "f80bb9147f6a4517afe4bc4a73d9275b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad30396a76a54b97be82b1fd30771750",
            "placeholder": "​",
            "style": "IPY_MODEL_12ecff4295744773929f8fa68f27512b",
            "value": " 605M/605M [00:02&lt;00:00, 242MB/s]"
          }
        },
        "094b3e5b9e9b427f8d5bed37821650f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efdf67b16312464c821a0763e6a7832f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97b46f71718645219064b9b3883ee178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eae1bc5070464391a343ddafb28d5ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54320831424f496ea4b32e86d706f536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad30396a76a54b97be82b1fd30771750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12ecff4295744773929f8fa68f27512b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azernik/semeval_2025_task1/blob/main/admire_generate_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and load data"
      ],
      "metadata": {
        "id": "9HDvXUFiHn9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# dev dataset\n",
        "file_id = \"1RCTQGF5DG0SmiU-GMYJ5owQ900BAsjno\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "gdown.download(url, \"taskA_dev.zip\", quiet=True)\n",
        "! unzip -q - taskA_dev.zip"
      ],
      "metadata": {
        "id": "fhczzv-RFL_G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# define locations\n",
        "taska_folder = \"dev\"\n",
        "taska_tsv_filename = \"subtask_a_dev.tsv\"\n",
        "\n",
        "# load data\n",
        "df = pd.read_csv(f\"{taska_folder}/{taska_tsv_filename}\", delimiter=\"\\t\")"
      ],
      "metadata": {
        "id": "63HsE3LgHlJy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For reference, not required\n",
        "\n",
        "df['sentence_type_true'] = [\n",
        "    'idiomatic',  # monkey business\n",
        "    'literal',    # grass roots\n",
        "    'literal',    # marching orders\n",
        "    'literal',    # panda car\n",
        "    'idiomatic',  # bread and butter\n",
        "    'literal',    # chocolate teapot\n",
        "    'idiomatic',  # pig's ear\n",
        "    'idiomatic',  # best man\n",
        "    'literal',    # big cheese\n",
        "    'idiomatic',  # eager beaver\n",
        "    'literal',    # hair of the dog\n",
        "    'idiomatic',  # thin ice\n",
        "    'idiomatic',  # snake in the grass\n",
        "    'literal',    # flea market\n",
        "    'literal',    # big fish\n",
        "]"
      ],
      "metadata": {
        "id": "Zt5H9jmsFS0Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df, dir_name):\n",
        "    \"\"\"\n",
        "    Loads and preprocesses the dataset, setting up image paths.\n",
        "    \"\"\"\n",
        "    image_name_cols = ['image1_name', 'image2_name', 'image3_name', 'image4_name', 'image5_name']\n",
        "    df['image_paths'] = df.apply(lambda row: [os.path.join(dir_name, row['compound'].replace(\"'\", \"_\"), row[image_name]) for image_name in image_name_cols], axis=1)\n",
        "    return df\n",
        "\n",
        "  df = preprocess_data(df, taska_folder)"
      ],
      "metadata": {
        "id": "_Iq1ywZfFV0_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For scoring\n",
        "\n",
        "df['top_1_true'] = [\n",
        "    '04129294826.png',  # image1 / monkey business\n",
        "    '88610497135.png',  # image5 / grass roots\n",
        "    '65125915005.png',  # image5 / marching orders\n",
        "    '38506509761.png',  # image3 / panda car\n",
        "    '98148844665.png',  # image5 (?) / bread and butter\n",
        "    '24249382249.png',  # image3 / chocolate teapot\n",
        "    '28970148854.png',  # image1 / pig's ear\n",
        "    '95555063454.png',  # image5 / best man\n",
        "    '22784021150.png',  # image3 / big cheese\n",
        "    '97713215186.png',  # image5 / eager beaver\n",
        "    '92505052147.png',  # image5 / hair of the dog\n",
        "    '66964681897.png',  # image4 / thin ice\n",
        "    '06740727918.png',  # image1 / snake in the grass\n",
        "    '70941962850.png',  # image5 / flea market\n",
        "    '66431812447.png',  # image / big fish\n",
        "]\n",
        "\n",
        "df['top_1_col'] = [\n",
        "    'image1',  # image1 / monkey business\n",
        "    'image5',  # image5 / grass roots\n",
        "    'image5',  # image5 / marching orders\n",
        "    'image3',  # image3 / panda car\n",
        "    'image5',  # image5 (?) / bread and butter\n",
        "    'image3',  # image3 / chocolate teapot\n",
        "    'image1',  # image1 / pig's ear\n",
        "    'image5',  # image5 / best man\n",
        "    'image3',  # image3 / big cheese\n",
        "    'image5',  # image5 / eager beaver\n",
        "    'image5',  # image5 / hair of the dog\n",
        "    'image4',  # image4 / thin ice\n",
        "    'image1',  # image1 / snake in the grass\n",
        "    'image5',  # image5 / flea market\n",
        "    'image3',  # image3 / big fish\n",
        "]"
      ],
      "metadata": {
        "id": "s_0NEP-Aveba"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text input generation"
      ],
      "metadata": {
        "id": "otLzgqFuKy4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "# OpenAI initialization\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_PROJECT_KEY'))"
      ],
      "metadata": {
        "id": "5fgXt-b3SbXu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT Prompt - Sentence type\n",
        "import json\n",
        "\n",
        "def gpt_sentence_types(compounds, sentences):\n",
        "    \"\"\"\n",
        "    Prompt GPT-4 to get the sentence type, literal or figurative, for a batch of sentences.\n",
        "    \"\"\"\n",
        "    # Create a combined prompt\n",
        "    samples = \"\\n\\n\".join([\n",
        "        f'Target phrase: \"{nc}\"\\nContext sentence: \"{sentence}\"' for nc, sentence in zip(compounds, sentences)\n",
        "    ])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a linguistics expert specializing in figurative language. You will be given a set of samples, each containing a \\\"target phrase\\\" paired with a \\\"context sentence\\\" containing a usage of said phrase.\n",
        "The target phrases all have idiomatic (i.e. figurative) meanings, but they might be used literally in these context sentences!\n",
        "For each sample, you are to do the following:\n",
        "1. Looking at the target phrase in isolation, state its *idiomatic* meaning and its *literal* meaning. The literal meaning might be awkward, as some of these phrases are almost always used idiomatically.\n",
        "2. *Carefully* consider how the target phrase is used in the context sentence. Is it used in its idiomatic sense (in most cases, they way that we\"re used to understanding it), or is it used as a literal composition of its component words?\n",
        "3. Verbose explanation: Given your familiarity with the phrase\"s possible meanings, and having considered how it\"s used in the sentence, give an explanation of what the phrase means in the context of the sentence. This can be a few sentences long.\n",
        "4. Final usage determination: Based on steps 1-3, state whether the phrase\"s use in the context sentence is \"literal\" or \"idiomatic\".\n",
        "\n",
        "Example input:\n",
        "Target phrase: \"cold turkey\"\n",
        "Context sentence: \"John quit smoking cold turkey and never looked back, not that it was easy.\"\n",
        "\n",
        "Target phrase: \"ghost town\"\n",
        "Context sentence: \"Our wanderings had led us perilously close to the walls of the ghost town where restless spirits haunted the streets, eager to absorb the vitatlity of the living.\"\n",
        "\n",
        "---\n",
        "\n",
        "Example response:\n",
        "{{\"samples\": [\n",
        "    {{\n",
        "      \"target_phrase\": \"cold turkey\",\n",
        "      \"idiomatic_meaning\": \"To stop a habit or addiction abruptly and completely, without gradually reducing or tapering off. It often refers to ceasing a harmful behavior or substance like smoking or drugs.\",\n",
        "      \"literal_meaning\": \"A cold dish made from turkey meat, often eaten as leftovers.\"\n",
        "      \"contextual_considerations\": \"In the sentence, \\\"John quit smoking cold turkey and never looked back, not that it was easy,\\\" the phrase \\\"cold turkey\\\" clearly does not refer to food. It is used in the context of quitting smoking, which aligns with the idiomatic usage of the term.\",\n",
        "      \"verbose_explanation\": \"The phrase \\\"cold turkey\\\" in this sentence means that John abruptly stopped smoking without tapering off or using substitutes like nicotine patches. The description highlights the difficulty of this approach, suggesting that quitting \\\"cold turkey\\\" was challenging but ultimately successful. The context does not mention anything about literal turkey, further affirming the idiomatic interpretation.\",\n",
        "      \"result\": \"idiomatic\"\n",
        "    }},\n",
        "    {{\n",
        "      \"target_phrase\": \"ghost town\",\n",
        "      \"idiomatic_meaning\": \"A deserted town or settlement that was once populated but is now abandoned, often evoking a sense of desolation or emptiness.\",\n",
        "      \"literal_meaning\": \"A town inhabited by ghosts or supernatural entities, as in fictional or mythological contexts.\"\n",
        "      \"contextual_considerations\": \"In the sentence, \\\"Our wanderings had led us perilously close to the walls of the ghost town where restless spirits haunted the streets, eager to absorb the vitality of the living,\\\" the description explicitly mentions \\\"restless spirits\\\" and their interaction with the living. This strongly suggests a literal interpretation involving supernatural elements.\",\n",
        "      \"verbose_explanation\": \"Here, \\\"ghost town\\\" refers to a literal place inhabited by ghosts or spirits, as indicated by the detailed imagery of \\\"restless spirits\\\" and their haunting presence. The context does not suggest the metaphorical use of the term as an abandoned, non-supernatural settlement.\",\n",
        "      \"result\": \"literal\"\n",
        "    }},\n",
        "    #...\n",
        "]}}\n",
        "\n",
        "---\n",
        "\n",
        "Output JSON schema:\n",
        "{{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {{\n",
        "    \"samples\": {{\n",
        "      \"type\": \"array\",\n",
        "      \"items\": {{\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {{\n",
        "          \"target_phrase\": {{\n",
        "            \"type\": \"string\"\n",
        "          }},\n",
        "          \"idiomatic_meaning\": {{\n",
        "            \"type\": \"string\"\n",
        "          }},\n",
        "          \"literal_meaning\": {{\n",
        "            \"type\": \"string\"\n",
        "          }},\n",
        "          \"contextual_considerations\": {{\n",
        "            \"type\": \"string\"\n",
        "          }},\n",
        "          \"verbose_explanation\": {{\n",
        "            \"type\": \"string\"\n",
        "          }},\n",
        "          \"result\": {{\n",
        "            \"type\": \"string\",\n",
        "            \"enum\": [\"idiomatic\", \"literal\"]\n",
        "          }}\n",
        "        }},\n",
        "        \"required\": [\n",
        "          \"target_phrase\",\n",
        "          \"idiomatic_meaning\",\n",
        "          \"literal_meaning\",\n",
        "          \"contextual_considerations\",\n",
        "          \"verbose_explanation\",\n",
        "          \"result\"\n",
        "        ]\n",
        "      }}\n",
        "    }}\n",
        "  }},\n",
        "  \"required\": [\"samples\"]\n",
        "}}\n",
        "\n",
        "Your turn. These are the samples:\n",
        "{samples}\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "    )\n",
        "    try:\n",
        "        raw_content = response.choices[0].message.content.strip()\n",
        "        # print(\"Raw GPT response:\", raw_content)  # Debug print\n",
        "        content = json.loads(raw_content)\n",
        "        print(json.dumps(content, indent=4))  # Debug formatted output\n",
        "        return content\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON decoding error: {e}\")\n",
        "        print(\"Response content that caused error:\", raw_content)\n",
        "        return {}"
      ],
      "metadata": {
        "id": "99DYyJWZSV2-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "results = {}\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch = df.iloc[i:i + batch_size]\n",
        "    compounds = batch['compound'].tolist()\n",
        "    sentences = batch['sentence'].tolist()\n",
        "    responses = gpt_sentence_types(compounds, sentences)\n",
        "    batch_results = {item[\"target_phrase\"]: item[\"result\"] for item in responses[\"samples\"]}\n",
        "    results.update(batch_results)\n",
        "\n",
        "df['sentence_type_pred'] = df['compound'].map(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9A4c6R8kbdKQ",
        "outputId": "a20c93ed-4403-4c50-8397-cfefc248346c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"samples\": [\n",
            "        {\n",
            "            \"target_phrase\": \"monkey business\",\n",
            "            \"idiomatic_meaning\": \"Dishonest or deceitful behavior, often involving trickery or non-transparent activities.\",\n",
            "            \"literal_meaning\": \"The actions or activities of monkeys.\",\n",
            "            \"contextual_considerations\": \"In this sentence, the phrase 'monkey business' is used within the context of describing a place's cleanliness and propriety. There is no suggestion of actual monkeys or their behaviors.\",\n",
            "            \"verbose_explanation\": \"In the given sentence, 'monkey business' is used to emphasize the propriety of the architectural environment referred to. The term implies that no illegal or underhanded activities occur there. No literal monkey-related action is mentioned or implied, thus it's indicative of the idiomatic use of the phrase.\",\n",
            "            \"result\": \"idiomatic\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"grass roots\",\n",
            "            \"idiomatic_meaning\": \"The most basic level of an activity or organization, often referring to the ordinary people as distinct from their leaders or organizers.\",\n",
            "            \"literal_meaning\": \"The part of the roots of a grass plant that is near the surface of the ground.\",\n",
            "            \"contextual_considerations\": \"The context sentence refers to roots of grass turning brown, which strongly implies the literal meaning.\",\n",
            "            \"verbose_explanation\": \"In this case, 'grass roots' is used to literally describe the roots of grass that may turn brown or black and begin to rot due to excess water or fungus. The context doesn't suggest the idiomatic meaning related to the base level or ordinary people within a social or political organization.\",\n",
            "            \"result\": \"literal\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"marching orders\",\n",
            "            \"idiomatic_meaning\": \"Instructions to leave a place or to do something; dismissal from employment or from a relationship.\",\n",
            "            \"literal_meaning\": \"Orders or instructions given to soldiers about where, when, and how to march.\",\n",
            "            \"contextual_considerations\": \"The phrase 'marching orders' is used in the context of soldiers awaiting commands from their general, pointing to the literal meaning of the phrase.\",\n",
            "            \"verbose_explanation\": \"In this sentence, 'marching orders' denotes the specific instructions awaited by soldiers from their commanding officer about how they are to march or move. This usage directly aligns with the phrase's literal understanding and does not suggest the idiomatic interpretation about dismissal or departure.\",\n",
            "            \"result\": \"literal\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"panda car\",\n",
            "            \"idiomatic_meaning\": \"In UK slang, a police car.\",\n",
            "            \"literal_meaning\": \"A car that bears resemblance to a panda, often due to its color pattern.\",\n",
            "            \"contextual_considerations\": \"The context sentence talks about a panda car, and then refers to black-and-white bears coming out, suggesting a literal interpretation.\",\n",
            "            \"verbose_explanation\": \"In this scenario, 'panda car' is interpreted in its literal sense to signify a vehicle that appears to have a connection to pandas, as emphasized by the succeeding phrase about black-and-white bears exiting the vehicle. The context does not suggest the British idiomatic use referring to police cars.\",\n",
            "            \"result\": \"literal\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"bread and butter\",\n",
            "            \"idiomatic_meaning\": \"A person\\u2019s main source of income or expertise; the work that someone relies on for their livelihood.\",\n",
            "            \"literal_meaning\": \"A common food made up of bread spread with butter.\",\n",
            "            \"contextual_considerations\": \"In the sentence, it is indicated that Steve's 'bread and butter' has been the same for a long time. Without suggesting any direct connection to food, this hints at the idiomatic meaning.\",\n",
            "            \"verbose_explanation\": \"In this context, 'bread and butter' refers to something Steve depends on as his main source of income. The phrase is used to emphasize that whatever it refers to is Steve's primary responsibility or focus, and there's no suggestion of literal bread or butter being involved.\",\n",
            "            \"result\": \"idiomatic\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"chocolate teapot\",\n",
            "            \"idiomatic_meaning\": \"A thing that is attractive but useless or impractical in a particular situation.\",\n",
            "            \"literal_meaning\": \"A teapot made out of chocolate.\",\n",
            "            \"contextual_considerations\": \"As the sentence talks about Lindt - a well-known chocolate manufacturer - making a chocolate teapot, this context implies a literal interpretation.\",\n",
            "            \"verbose_explanation\": \"In this case, 'chocolate teapot' literally describes a teapot made of chocolate. Lindt is a chocolate manufacturer and the whole context is about a promotional campaign they did, reinforcing the literal interpretation and not pointing toward the idiomatic interpretation about something worthless or impractical.\",\n",
            "            \"result\": \"literal\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"pig's ear\",\n",
            "            \"idiomatic_meaning\": \"A situation, task, or thing which has been handled or carried out clumsily or ineptly.\",\n",
            "            \"literal_meaning\": \"The ear of a pig.\",\n",
            "            \"contextual_considerations\": \"The phrase 'pig's ear' is used in relation to writing a partition table, indicating an idiomatic use.\",\n",
            "            \"verbose_explanation\": \"In this context, 'pig's ear' signifies that the writing of the new partition table was carried out clumsily, poorly, or inappropriately. It doesn't refer to the literal ear of a pig, but uses the idiomatic usage to convey the bungling or mishandling of the task.\",\n",
            "            \"result\": \"idiomatic\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"best man\",\n",
            "            \"idiomatic_meaning\": \"The chief male attendant to the groom at a wedding, typically a close friend or sibling.\",\n",
            "            \"literal_meaning\": \"The man who is superior to all others.\",\n",
            "            \"contextual_considerations\": \"The context sentence refers to the speaker being asked to be Neil's best man in a setting that alludes to a wedding, suggesting the idiomatic meaning.\",\n",
            "            \"verbose_explanation\": \"In this sentence, 'best man' denotes the role of the primary male attendant or supporter of the groom in a wedding tradition. The mention of Neil asking his friend to be his 'best man' clearly points to this specific wedding custom oppose to the literal interpretation of being the superior male.\",\n",
            "            \"result\": \"idiomatic\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"big cheese\",\n",
            "            \"idiomatic_meaning\": \"A very important or influential person in a group or organization.\",\n",
            "            \"literal_meaning\": \"An exceptionally large piece of cheese.\",\n",
            "            \"contextual_considerations\": \"In the sentence, the phrase 'big cheese' is used in connection with sending something to Ticknor, which implies the literal meaning of a large piece of cheese.\",\n",
            "            \"verbose_explanation\": \"In this context, the 'big cheese' is literally a large cheese that the speaker is sending to Ticknor. The speaker also suggests that Ticknor share it with others, reinforcing the literal use of the phrase rather than the idiomatic understanding of a powerful or influential person.\",\n",
            "            \"result\": \"literal\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"eager beaver\",\n",
            "            \"idiomatic_meaning\": \"A keen and enthusiastic person who works very hard.\",\n",
            "            \"literal_meaning\": \"A beaver that displays eagerness.\",\n",
            "            \"contextual_considerations\": \"The phrase 'eager beaver' is used in the sentence to describe young staffers, indicating the idiomatic meaning.\",\n",
            "            \"verbose_explanation\": \"In this sentence, 'eager beaver' characterizes the young staffers as enthusiastic and hardworking. The context doesn't point to any literal beavers, but uses the idiomatic meaning to convey the energy and readiness of the staff to work on the mentioned task.\",\n",
            "            \"result\": \"idiomatic\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"samples\": [\n",
            "        {\n",
            "            \"target_phrase\": \"hair of the dog\",\n",
            "            \"idiomatic_meaning\": \"A method of curing a hangover by consuming more alcohol.\",\n",
            "            \"literal_meaning\": \"The fur or hair that covers a dog's body.\",\n",
            "            \"contextual_considerations\": \"The phrase 'hair of the dog' in the context sentence is used to literally describe an aspect of a puppy, making no reference to alcohol consumption or hangovers. The phrase is used to take on its literal meaning in the sentence\",\n",
            "            \"verbose_explanation\": \"In the sentence 'The puppy was so fluffy, it was difficult to differentiate between the hair of the dog and the plush toys in the room', the phrase 'hair of the dog' is used to refer to the physical fur of a puppy rather than its idiomatic usage of consuming alcohol to ward off a hangover.\",\n",
            "            \"result\": \"literal\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"thin ice\",\n",
            "            \"idiomatic_meaning\": \"Taking a risk or doing something dangerous that can potentially lead to trouble or disaster.\",\n",
            "            \"literal_meaning\": \"A frozen mass of water with insufficient thickness to support weight.\",\n",
            "            \"contextual_considerations\": \"The phrase 'thin ice' is used in the context sentence metaphorically, referring to the precarious situation investors find themselves in, not literally referring to a body of water in its frozen state.\",\n",
            "            \"verbose_explanation\": \"In the sentence, 'Investors in both instances were already tiptoeing on thin ice, knowing that the longest US stock market bull run in history was showing signs of overheating,', 'thin ice' is used to indicate the risk and potential danger investors are facing due to an overheating stock market. Thus, in this context, 'thin ice' is used to evoke a sense of impending disaster for those taking risks.\",\n",
            "            \"result\": \"idiomatic\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"snake in the grass\",\n",
            "            \"idiomatic_meaning\": \"An insincere, deceitful and treacherous person who pretends to be trustworthy.\",\n",
            "            \"literal_meaning\": \"A serpent that is located in grass.\",\n",
            "            \"contextual_considerations\": \"In the sentence provided, 'snake in the grass' refers to a person, not an actual snake. The behavior of this person aligns with the idomatic meaning of the phrase.\",\n",
            "            \"verbose_explanation\": \"In the context, 'A ruthless snake in the grass, he desires power and status, but lacks the drive to obtain them through skill alone, and instead sucks up to his superiors in hopes of passively winning their favor.' 'snake in the grass' is an idiomatic usage meaning a deceitful or treacherous person. The surrounding context supports this interpretation, as the person described is said to desire power and status through insincere means.\",\n",
            "            \"result\": \"idiomatic\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"flea market\",\n",
            "            \"idiomatic_meaning\": \"A market, usually taking place outdoors, where second-hand or discounted goods are sold.\",\n",
            "            \"literal_meaning\": \"An actual market where fleas are sold or traded.\",\n",
            "            \"contextual_considerations\": \"In the context sentence provided, 'flea market' refers to an actual market or venue where fleas and other insects are being sold, which aligns with its literal meaning.\",\n",
            "            \"verbose_explanation\": \"In this sentence, 'The flea market was bustling with people inspecting cages of tiny insects while vendors talked up their jumping abilities.', 'flea market' is used literally to describe a market where people are inspecting and buying fleas and other insects. The surrounding context supports the literal meaning, as it discusses sellers promoting the fleas' jumping abilities, something typical of actual fleas and not second-hand or discount goods.\",\n",
            "            \"result\": \"literal\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"big fish\",\n",
            "            \"idiomatic_meaning\": \"An important or influential person, often in a specific field or industry.\",\n",
            "            \"literal_meaning\": \"A fish that is large in size.\",\n",
            "            \"contextual_considerations\": \"In this context, 'big fish' is used in its literal meaning to refer to a fish that is large. There's no indication that it is used to describe an influential person.\",\n",
            "            \"verbose_explanation\": \"In the sentence 'We had our picturesque winter sunsets, big fish held out for pictures before we put them back down the hole, and images of the two of us.', 'big fish' is used to mean actual large fish that have been caught and then released, as indicated by the action of holding them out for pictures and then putting them back down the fishing hole.\",\n",
            "            \"result\": \"literal\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT Prompt #2\n",
        "import json\n",
        "\n",
        "def gpt_definitions(compounds, sentence_types):\n",
        "    \"\"\"\n",
        "    Generate definitions for target phrases using GPT-4, in batches.\n",
        "    \"\"\"\n",
        "    # Filter out literals since they don't need processing\n",
        "    input_data = [\n",
        "        nc for nc, sentence_type in zip(compounds, sentence_types) if sentence_type != \"literal\"\n",
        "    ]\n",
        "\n",
        "    # Skip batch if all are literal\n",
        "    if not input_data:\n",
        "        return {nc: nc for nc in compounds}  # Return original NCs for all literals\n",
        "\n",
        "    # Create a combined prompt\n",
        "    examples = \"\\n\".join([\n",
        "        f'The idiom is: \"{nc}\".' for nc in input_data\n",
        "    ])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a linguistics expert specializing in idioms. For each of the idioms below, do the following steps aloud (in writing):\n",
        "1. Give a verbose explanation of the idiom, including what connotations it carries or undertones it evokes.\n",
        "2. Taking into consideration your response for #1, list three potential definitions, no longer than 20 words each, that capture the underlying idea conveyed by the idiom, without referencing it as an idiom, figure of speech, or stylistic expression.\n",
        "3. Choose the best definition.\n",
        "\n",
        "Example inputs:\n",
        "The idiom is: \"cold turkey\"\n",
        "The idiom is: \"bun in the oven\"\n",
        "The idiom is: \"shrinking violet\"\n",
        "\n",
        "---\n",
        "\n",
        "Example output:\n",
        "{{\"samples\": [\n",
        "    {{\n",
        "      \"target_phrase\": \"cold turkey\",\n",
        "      \"explanation\": \"Refers to abruptly stopping a behavior, typically a bad habit, without gradual reduction or preparation. Evokes starkness, discomfort, determination, hardship, and raw honesty. Often associated with quitting addictive substances or habits, emphasizing suddenness and self-discipline.\",\n",
        "      \"potential_definition_1\": \"Immediately ceasing a habit or behavior without any preparation.\",\n",
        "      \"potential_definition_2\": \"Stopping something abruptly, often in a challenging or uncomfortable manner.\",\n",
        "      \"potential_definition_3\": \"Making a sharp and decisive change, particularly to quit a dependency.\",\n",
        "      \"result\": \"Stopping something abruptly, often in a challenging or uncomfortable manner.\"\n",
        "    }},\n",
        "    {{\n",
        "      \"target_phrase\": \"bun in the oven\",\n",
        "      \"explanation\": \"A lighthearted, euphemistic way to say someone is pregnant. Carries warm, nurturing undertones, invoking growth, expectancy, and care. Sometimes used to hint at pregnancy rather than explicitly state it, implying secrecy or anticipation.\",\n",
        "      \"potential_definition_1\": \"Expecting the arrival of a new baby or nurturing a life in progress.\",\n",
        "      \"potential_definition_2\": \"A situation where growth and development are underway.\",\n",
        "      \"potential_definition_3\": \"Preparing for an important, life-changing event, particularly childbirth.\",\n",
        "      \"result\": \"Expecting the arrival of a new baby or nurturing a life in progress.\"\n",
        "    }},\n",
        "    {{\n",
        "      \"target_phrase\": \"shrinking violet\",\n",
        "      \"explanation\": \"Describes someone who is exceptionally shy, reserved, or introverted, often avoiding attention or interaction. Connotations of delicacy, modesty, and a lack of assertiveness. Sometimes evokes frustration or pity due to extreme timidity or unconfidence.\",\n",
        "      \"potential_definition_1\": \"A person who is extremely shy and avoids attention or interaction.\",\n",
        "      \"potential_definition_2\": \"Someone whose reserved nature makes them hesitant to assert themselves.\",\n",
        "      \"potential_definition_3\": \"A timid individual who prefers to stay out of the spotlight.\",\n",
        "      \"result\": \"A person who is extremely shy and avoids attention or interaction.\"\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "\n",
        "---\n",
        "\n",
        "Output JSON schema:\n",
        "{{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {{\n",
        "    \"samples\": {{\n",
        "      \"type\": \"array\",\n",
        "      \"items\": {{\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {{\n",
        "          \"target_phrase\": {{\n",
        "            \"type\": \"string\"\n",
        "          }},\n",
        "          \"explanation\": {{\n",
        "            \"type\": \"string\"\n",
        "          }},\n",
        "          \"potential_definition_1\": {{\n",
        "            \"type\": \"string\"\n",
        "          }},\n",
        "          \"potential_definition_2\": {{\n",
        "            \"type\": \"string\"\n",
        "          }},\n",
        "          \"potential_definition_3\": {{\n",
        "            \"type\": \"string\"\n",
        "          }},\n",
        "          \"result\": {{\n",
        "            \"type\": \"string\"\n",
        "          }}\n",
        "        }},\n",
        "        \"required\": [\n",
        "          \"target_phrase\",\n",
        "          \"explanation\",\n",
        "          \"potential_definition_1\",\n",
        "          \"potential_definition_2\",\n",
        "          \"potential_definition_3\",\n",
        "          \"result\"\n",
        "        ]\n",
        "      }}\n",
        "    }}\n",
        "  }},\n",
        "  \"required\": [\"samples\"]\n",
        "}}\n",
        "\n",
        "Your turn. Here are the samples:\n",
        "{examples}\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "    )\n",
        "    try:\n",
        "        raw_content = response.choices[0].message.content.strip()\n",
        "        # print(\"Raw GPT response:\", raw_content)  # Debug print\n",
        "        content = json.loads(raw_content)\n",
        "        print(json.dumps(content, indent=4))  # Debug formatted output\n",
        "        return content\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON decoding error: {e}\")\n",
        "        print(\"Response content that caused error:\", raw_content)\n",
        "        return {}"
      ],
      "metadata": {
        "id": "IcX2yhzeK3tq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to the DataFrame in batches\n",
        "batch_size = 10\n",
        "results = {}\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch = df.iloc[i:i + batch_size]\n",
        "    compounds = batch['compound'].tolist()\n",
        "    sentence_types = batch['sentence_type_pred'].tolist()\n",
        "    responses = gpt_definitions(compounds, sentence_types)\n",
        "    batch_results = {item[\"target_phrase\"]: item[\"result\"] for item in responses[\"samples\"]}\n",
        "    results.update(batch_results)\n",
        "\n",
        "# Map results back to DataFrame\n",
        "df['text_input'] = df['compound'].map(results)\n",
        "df['text_input'].fillna(df['compound'], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dUuIFmXdMRv_",
        "outputId": "cb5890b2-ac54-41bd-cfbb-3839d6b5a5d2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"samples\": [\n",
            "        {\n",
            "            \"target_phrase\": \"monkey business\",\n",
            "            \"explanation\": \"Refers to actions or behavior that are deceitful, dishonest, or not to be taken seriously. Often implies mischief, tomfoolery, or irresponsibility. Mostly used to denote unethical undertakings or the initiation of a senseless mess.\",\n",
            "            \"potential_definition_1\": \"Dishonest, mischievous, or foolish behavior.\",\n",
            "            \"potential_definition_2\": \"Actions taken in a dishonest or underhanded manner.\",\n",
            "            \"potential_definition_3\": \"Behavior that is not to be taken seriously, often due to mischief.\",\n",
            "            \"result\": \"Dishonest, mischievous, or foolish behavior.\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"bread and butter\",\n",
            "            \"explanation\": \"Used to describe a person's main and steady source of income. Can also signify someone's basic needs or the thing which they primarily rely upon. Often has connotations of simplicity, necessity, and regularity.\",\n",
            "            \"potential_definition_1\": \"Someone's primary source of earnings or livelihood.\",\n",
            "            \"potential_definition_2\": \"The main thing someone relies on for their necessities.\",\n",
            "            \"potential_definition_3\": \"A straightforward and reliable means of income or sustenance.\",\n",
            "            \"result\": \"Someone's primary source of earnings or livelihood.\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"pig's ear\",\n",
            "            \"explanation\": \"Traditionally a British idiom, 'to make a pig's ear out of something' means making a mess or blunder, typically by performing a task poorly. It carries undertones of clumsiness, incompetence, and generally bad workmanship.\",\n",
            "            \"potential_definition_1\": \"Creating a mess due to poor effort or incompetence.\",\n",
            "            \"potential_definition_2\": \"Fumbling or failing at a task, resulting in a blunder.\",\n",
            "            \"potential_definition_3\": \"Making a situation worse by poor handling or lack of skill.\",\n",
            "            \"result\": \"Creating a mess due to poor effort or incompetence.\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"best man\",\n",
            "            \"explanation\": \"This term is usually specific to Western weddings. The 'best man' is the groom's closest male confidant, usually a best friend or brother, who assists the groom before, during, and after the wedding ceremony. It implies trust, camaraderie, and responsibility.\",\n",
            "            \"potential_definition_1\": \"A prominent male participant at a wedding, in support of the groom.\",\n",
            "            \"potential_definition_2\": \"A groom's close friend or brother who assists during the wedding.\",\n",
            "            \"potential_definition_3\": \"An individual entrusted with supporting the groom at a wedding.\",\n",
            "            \"result\": \"A groom's close friend or brother who assists during the wedding.\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"eager beaver\",\n",
            "            \"explanation\": \"Used to describe a person who is enthusiastic, hard-working, and zealous, often to the point of being overzealous. It carries a sense of industriousness, initiative, but also may imply a lack of patience, or over-eagerness which might annoy others.\",\n",
            "            \"potential_definition_1\": \"An individual who shows excessive enthusiasm or initiative.\",\n",
            "            \"potential_definition_2\": \"A person who works hard and is overly eager to please.\",\n",
            "            \"potential_definition_3\": \"An overzealous or very industrious person who may lack patience.\",\n",
            "            \"result\": \"An individual who shows excessive enthusiasm or initiative.\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"samples\": [\n",
            "        {\n",
            "            \"target_phrase\": \"thin ice\",\n",
            "            \"explanation\": \"This term is typically used to suggest that one is in a dangerous, risky, or insecure situation that may result in trouble or disaster if continued. Associated with the tension, caution, and fragility of such situations. It conveys the idea that one's current path or actions might lead to danger, just as walking on thin ice risks breaking through and falling into cold water.\",\n",
            "            \"potential_definition_1\": \"In a perilous or risky situation that could quickly become problematic.\",\n",
            "            \"potential_definition_2\": \"Behaving or acting in a manner that might lead to dire consequences.\",\n",
            "            \"potential_definition_3\": \"Persisting in a precarious situation that might result in danger or disaster.\",\n",
            "            \"result\": \"In a perilous or risky situation that could quickly become problematic.\"\n",
            "        },\n",
            "        {\n",
            "            \"target_phrase\": \"snake in the grass\",\n",
            "            \"explanation\": \"Refers to a person who pretends to be your friend but is actually untrustworthy, deceitful, or disloyal. It evokes strong feelings of treachery, hidden danger, and betrayal. The image of a snake hiding in the grass suggests the concealed danger and surprise one experiences when such true intentions are revealed.\",\n",
            "            \"potential_definition_1\": \"A disloyal or deceitful person who pretends to be trustworthy.\",\n",
            "            \"potential_definition_2\": \"An individual who hides their true malicious or deceitful intentions.\",\n",
            "            \"potential_definition_3\": \"A person who presents as a friend but is treacherous or dishonest.\",\n",
            "            \"result\": \"A disloyal or deceitful person who pretends to be trustworthy.\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-2834f7bb7aff>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['text_input'].fillna(df['compound'], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execution"
      ],
      "metadata": {
        "id": "rs50-mlfJmFM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Image-ranking functions"
      ],
      "metadata": {
        "id": "NeWcJp0LFX3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install anyio==3.5.0 openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
      ],
      "metadata": {
        "id": "seWudX2yKt9e"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install clip\n",
        "!pip install -q ftfy regex tqdm\n",
        "!pip install -q git+https://github.com/openai/CLIP.git\n",
        "\n",
        "import clip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xcfEa1tKpe-",
        "outputId": "7272f194-c36b-470a-cb48-ff692ada91ea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from ast import literal_eval\n",
        "\n",
        "def get_image_ranking_clip(model, image_processor, image_paths, sentence):\n",
        "    image_inputs = torch.stack([image_processor(Image.open(ipath)) for ipath in image_paths]).to(device)\n",
        "    text_input = clip.tokenize(sentence).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # compute embeddings\n",
        "        image_features = model.encode_image(image_inputs)\n",
        "        text_features = model.encode_text(text_input)\n",
        "\n",
        "    # normalize features\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # compute similarity scores\n",
        "    similarity = (100.0 * text_features @ image_features.T).softmax(dim=-1)\n",
        "\n",
        "    # rank images by similarity\n",
        "    probs, indices = similarity[0].topk(5)\n",
        "    return probs, indices"
      ],
      "metadata": {
        "id": "NGdxPA8VFZaR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def openclip_image_ranking(model, image_processor, tokenizer, image_paths, sentence):\n",
        "    image_inputs = torch.stack([preprocess_openclip(Image.open(ipath)) for ipath in image_paths]).to(device)\n",
        "    text_input = tokenizer([sentence]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        image_features = model.encode_image(image_inputs)\n",
        "        text_features = model.encode_text(text_input)\n",
        "\n",
        "    # normalise features\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # dot product & softmax\n",
        "    similarity = (100.0 * text_features @ image_features.T).softmax(dim=-1)\n",
        "\n",
        "    # order by similarity\n",
        "    probs, indices = similarity[0].topk(5)\n",
        "    return probs, indices"
      ],
      "metadata": {
        "id": "mS8JKUsuFdp-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_ranking_align(model, processor, image_paths, sentence):\n",
        "    image_inputs = [Image.open(ipath) for ipath in image_paths]\n",
        "    inputs = processor(images=image_inputs ,text=sentence, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits_per_text = outputs.logits_per_text[0]\n",
        "    probs = logits_per_text.softmax(dim=-1)\n",
        "    ids_sorted = torch.argsort(probs, descending=True)\n",
        "    return probs[ids_sorted], ids_sorted"
      ],
      "metadata": {
        "id": "WdvjrNYHFcXK"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model config"
      ],
      "metadata": {
        "id": "xHFQSJlVGCQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "2IDOr4CkJ2KN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open_clip_torch\n",
        "import open_clip\n",
        "\n",
        "openclip_model_version = \"ViT-B-32\"\n",
        "model_openclip, _, preprocess_openclip = open_clip.create_model_and_transforms(openclip_model_version, pretrained='laion2b_s34b_b79k')\n",
        "model_openclip.to(device)\n",
        "open_clip_tokenizer = open_clip.get_tokenizer(openclip_model_version)\n",
        "model_openclip.eval()  # model in train mode by default, impacts some models with BatchNorm or stochastic depth active"
      ],
      "metadata": {
        "id": "xx4nxTbUFvvN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0f66ed17473c4433ae9f92a2d92271ec",
            "91d80297ba3b4a6a99937ad1b6249dad",
            "efccf5a62ef8474ea8b786ee5f86bf65",
            "f80bb9147f6a4517afe4bc4a73d9275b",
            "094b3e5b9e9b427f8d5bed37821650f9",
            "efdf67b16312464c821a0763e6a7832f",
            "97b46f71718645219064b9b3883ee178",
            "eae1bc5070464391a343ddafb28d5ba9",
            "54320831424f496ea4b32e86d706f536",
            "ad30396a76a54b97be82b1fd30771750",
            "12ecff4295744773929f8fa68f27512b"
          ]
        },
        "collapsed": true,
        "outputId": "ae4aa487-7caf-40a7-890c-bdc741a7e102"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open_clip_torch\n",
            "  Downloading open_clip_torch-2.29.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.20.1+cu121)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2024.11.6)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (6.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.27.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.4.5)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (1.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->open_clip_torch) (1.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch) (0.2.13)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2024.12.14)\n",
            "Downloading open_clip_torch-2.29.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: open_clip_torch\n",
            "Successfully installed open_clip_torch-2.29.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "open_clip_pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f66ed17473c4433ae9f92a2d92271ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLIP(\n",
              "  (visual): VisionTransformer(\n",
              "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
              "    (patch_dropout): Identity()\n",
              "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (transformer): Transformer(\n",
              "      (resblocks): ModuleList(\n",
              "        (0-11): 12 x ResidualAttentionBlock(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ls_1): Identity()\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): GELU(approximate='none')\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ls_2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (transformer): Transformer(\n",
              "    (resblocks): ModuleList(\n",
              "      (0-11): 12 x ResidualAttentionBlock(\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ls_1): Identity()\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): GELU(approximate='none')\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ls_2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (token_embedding): Embedding(49408, 512)\n",
              "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlignProcessor, AlignModel\n",
        "\n",
        "models = [\n",
        "    # {\n",
        "    #     \"base_model\": \"CLIP\",\n",
        "    #     \"model_name\": \"ViT-B/32\",\n",
        "    #     \"model\": clip.load(\"ViT-B/32\", device)[0],\n",
        "    #     \"preprocess\": clip.load(\"ViT-B/32\", device)[1]\n",
        "    # },\n",
        "    # {\n",
        "    #     \"base_model\": \"CLIP\",\n",
        "    #     \"model_name\": \"ViT-L/14\",\n",
        "    #     \"model\": clip.load(\"ViT-L/14\", device)[0],\n",
        "    #     \"preprocess\": clip.load(\"ViT-L/14\", device)[1]\n",
        "    # },\n",
        "    {\n",
        "        \"base_model\": \"CLIP\",\n",
        "        \"model_name\": \"RN50x64\",\n",
        "        \"model\": clip.load(\"RN50x64\", device)[0],\n",
        "        \"preprocess\": clip.load(\"RN50x64\", device)[1]\n",
        "    },\n",
        "    # {\n",
        "    #     \"base_model\": \"Align\",\n",
        "    #     \"model_name\": \"Base\",\n",
        "    #     \"model\": AlignModel.from_pretrained(\"kakaobrain/align-base\"),\n",
        "    #     \"preprocess\": AlignProcessor.from_pretrained(\"kakaobrain/align-base\")\n",
        "    # },\n",
        "    {\n",
        "        \"base_model\": \"open_clip\",\n",
        "        \"model_name\": openclip_model_version,\n",
        "        \"model\": model_openclip,\n",
        "        \"preprocess\": preprocess_openclip,\n",
        "        \"tokenizer\": open_clip_tokenizer,\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "VKmdk5YOF9p3"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, processor, image_paths_list, text_inputs, base_model, model_name, tokenizer=None):\n",
        "    \"\"\"\n",
        "    Uses get_image_ranking to generate predictions and confidence scores for a image-list, text-input pairs\n",
        "    \"\"\"\n",
        "    predictions, confidence_scores = [], []\n",
        "\n",
        "    for ipaths, text in zip(image_paths_list, text_inputs):\n",
        "        if len(ipaths) == 0:\n",
        "            predictions.append([])\n",
        "            confidence_scores.append([])\n",
        "            continue\n",
        "\n",
        "        # values, indices = get_image_ranking(ipaths, text)\n",
        "        if base_model == \"CLIP\":\n",
        "          values, indices = get_image_ranking_clip(model, processor, ipaths, text)\n",
        "        elif base_model == \"Align\":\n",
        "          values, indices = get_image_ranking_align(model, processor, ipaths, text)\n",
        "        elif base_model == \"open_clip\":\n",
        "          values, indices = openclip_image_ranking(model, processor, tokenizer, ipaths, text)\n",
        "        else:\n",
        "          raise ValueError(f\"Unknown base_model: {base_model}\")\n",
        "        predictions.append(list(indices.cpu()))\n",
        "        confidence_scores.append(100 * values)\n",
        "\n",
        "    return predictions, confidence_scores\n"
      ],
      "metadata": {
        "id": "GRAFMw6-JbcT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_test(df, model, processor, base_model, model_name, output_file, tokenizer=None):\n",
        "    \"\"\"\n",
        "    Generates predictions using the provided model and saves the output as a TSV.\n",
        "    \"\"\"\n",
        "    # Generate predictions\n",
        "    predictions, confidence_scores = get_predictions(\n",
        "        model=model,\n",
        "        processor=processor,\n",
        "        image_paths_list=df['image_paths'],\n",
        "        text_inputs=df['text_input'],\n",
        "        base_model=base_model,\n",
        "        model_name=model_name\n",
        "    )\n",
        "\n",
        "    write_submission_file(df, predictions, confidence_scores, output_file)"
      ],
      "metadata": {
        "id": "ZIah2saTIz29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "\n",
        "model_config = models[0] # CLIP RN50x64\n",
        "# model_config = models[1] # OpenCLIP ViT-B-32\n",
        "\n",
        "predictions, confidence_scores = get_predictions(\n",
        "    model=model_config['model'],\n",
        "    processor=model_config['preprocess'],\n",
        "    image_paths_list=df['image_paths'],\n",
        "    text_inputs=df['text_input'],\n",
        "    base_model=model_config['base_model'],\n",
        "    model_name=model_config['model_name']\n",
        ")"
      ],
      "metadata": {
        "id": "bouubIrV_bjM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.read_csv(f\"{taska_folder}/{taska_tsv_filename}\", delimiter=\"\\t\")\n",
        "submission_df = submission_df[['compound', 'expected_order']]\n",
        "\n",
        "formatted_results = []\n",
        "\n",
        "# Iterate over predictions and confidence scores\n",
        "for i, (pred, conf) in enumerate(zip(predictions, confidence_scores)):\n",
        "    # Get ranked file names\n",
        "    ranked_files = [os.path.basename(df['image_paths'].iloc[i][j]) for j in pred]\n",
        "\n",
        "    # Update the df DataFrame with the expected order as a Python-style list string\n",
        "    submission_df.loc[i, 'expected_order'] = str(ranked_files)\n",
        "\n",
        "    # Create a formatted result for results_df\n",
        "    formatted_results.append({\n",
        "        \"index\": i,\n",
        "        \"compound\": df[\"compound\"].iloc[i],\n",
        "        \"ranked_image_files\": \" \".join(ranked_files),\n",
        "        \"confidence_scores\": \" \".join(map(lambda x: f\"{x:.3f}\", conf))\n",
        "    })\n",
        "\n",
        "submission_df.to_csv('submission_EN.tsv', sep=\"\\t\", index=False)\n",
        "\n",
        "# For further inspection, uncomment\n",
        "# results_df = pd.DataFrame(formatted_results)\n",
        "# results_df['top_1_pred'] = results_df['ranked_image_files'].apply(lambda x: x.split()[0])\n",
        "# results_df['top_1_true'] = df['top_1_true']\n",
        "# results_df['top1_correct'] = results_df['top_1_true'] == results_df['top_1_pred']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSBeIq6VDd13",
        "outputId": "01a8d2b5-da3d-482a-a6ea-7d71e962c7e4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-76-074ca8fd4656>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['04129294826.png', '94990180734.png', '61570020623.png', '33778559524.png', '56875274126.png']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df_raw.loc[i, 'expected_order'] = str(ranked_files)\n"
          ]
        }
      ]
    }
  ]
}